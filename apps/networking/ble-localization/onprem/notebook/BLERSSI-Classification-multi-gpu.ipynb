{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLE RSSI Dataset for Indoor localization\n",
    "\n",
    "The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The following figure depicts the layout of the iBeacons as well as the arrange of locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pictures/iBeacon_Layout.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.6/site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas sklearn --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number of available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLE_RSSI = pd.read_csv('iBeacon_RSSI_Labeled.csv') #Labeled dataset\n",
    "\n",
    "# Configure model options\n",
    "TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/tmp/data/\")\n",
    "TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"blerssi/\")\n",
    "TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"blerssi/\")\n",
    "TF_MODEL_TYPE = os.getenv(\"TF_MODEL_TYPE\", \"DNN\")\n",
    "TF_TRAIN_STEPS = int(os.getenv(\"TF_TRAIN_STEPS\", 500))\n",
    "TF_BATCH_SIZE = int(os.getenv(\"TF_BATCH_SIZE\", 50))\n",
    "TF_LEARNING_RATE = float(os.getenv(\"TF_LEARNING_RATE\", 0.001))\n",
    "\n",
    "\n",
    "# Feature columns\n",
    "COLUMNS = list(BLE_RSSI.columns)\n",
    "FEATURES = COLUMNS[2:]\n",
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLERSSI Input Dataset\n",
    "\n",
    "### Attribute Information\n",
    "\n",
    "    location: The location of receiving RSSIs from ibeacons b3001 to b3013; \n",
    "              symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1).\n",
    "    date: Datetime in the format of ‘d-m-yyyy hh:mm:ss’\n",
    "    b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>b3001</th>\n",
       "      <th>b3002</th>\n",
       "      <th>b3003</th>\n",
       "      <th>b3004</th>\n",
       "      <th>b3005</th>\n",
       "      <th>b3006</th>\n",
       "      <th>b3007</th>\n",
       "      <th>b3008</th>\n",
       "      <th>b3009</th>\n",
       "      <th>b3010</th>\n",
       "      <th>b3011</th>\n",
       "      <th>b3012</th>\n",
       "      <th>b3013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O02</td>\n",
       "      <td>10-18-2016 11:15:21</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-78</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:19</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-78</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:17</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:15</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:13</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:11</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-82</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:09</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-80</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P02</td>\n",
       "      <td>10-18-2016 11:15:07</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-86</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R01</td>\n",
       "      <td>10-18-2016 11:15:05</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-75</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R01</td>\n",
       "      <td>10-18-2016 11:15:03</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-75</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                 date  b3001  b3002  b3003  b3004  b3005  b3006  \\\n",
       "0      O02  10-18-2016 11:15:21   -200   -200   -200   -200   -200    -78   \n",
       "1      P01  10-18-2016 11:15:19   -200   -200   -200   -200   -200    -78   \n",
       "2      P01  10-18-2016 11:15:17   -200   -200   -200   -200   -200    -77   \n",
       "3      P01  10-18-2016 11:15:15   -200   -200   -200   -200   -200    -77   \n",
       "4      P01  10-18-2016 11:15:13   -200   -200   -200   -200   -200    -77   \n",
       "5      P01  10-18-2016 11:15:11   -200   -200    -82   -200   -200   -200   \n",
       "6      P01  10-18-2016 11:15:09   -200   -200    -80   -200   -200    -77   \n",
       "7      P02  10-18-2016 11:15:07   -200   -200    -86   -200   -200   -200   \n",
       "8      R01  10-18-2016 11:15:05   -200   -200   -200    -75   -200   -200   \n",
       "9      R01  10-18-2016 11:15:03   -200   -200   -200    -75   -200   -200   \n",
       "\n",
       "   b3007  b3008  b3009  b3010  b3011  b3012  b3013  \n",
       "0   -200   -200   -200   -200   -200   -200   -200  \n",
       "1   -200   -200   -200   -200   -200   -200   -200  \n",
       "2   -200   -200   -200   -200   -200   -200   -200  \n",
       "3   -200   -200   -200   -200   -200   -200   -200  \n",
       "4   -200   -200   -200   -200   -200   -200   -200  \n",
       "5   -200   -200   -200   -200   -200   -200   -200  \n",
       "6   -200   -200   -200   -200   -200   -200   -200  \n",
       "7   -200   -200   -200   -200   -200   -200   -200  \n",
       "8   -200   -200   -200   -200   -200   -200   -200  \n",
       "9   -200   -200   -200   -200   -200   -200   -200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLE_RSSI.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Serving Input Receiver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns =  make_feature_cols()\n",
    "inputs = {}\n",
    "for feat in feature_columns:\n",
    "  inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)\n",
    "serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save BLE RSSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'blerssi/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 object at 0x7fc7d8b33a90>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc7d8b33da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Partitioned variables are disabled when using current tf.distribute.Strategy.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into blerssi/model.ckpt.\n",
      "INFO:tensorflow:loss = 592.26196, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 100 into blerssi/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-13T13:07:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-13-13:07:45\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.23053798, average_loss = 2.4569528, global_step = 100, loss = 155.27942\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: blerssi/model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 59.8582\n",
      "INFO:tensorflow:loss = 320.6826, step = 100 (1.671 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into blerssi/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-13T13:07:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-13-13:07:47\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.25237343, average_loss = 2.3847842, global_step = 200, loss = 150.71835\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: blerssi/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 61.8215\n",
      "INFO:tensorflow:loss = 308.33136, step = 200 (1.618 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into blerssi/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-13T13:07:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-13-13:07:48\n",
      "INFO:tensorflow:Saving dict for global step 300: accuracy = 0.2550633, average_loss = 2.3391147, global_step = 300, loss = 147.83205\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: blerssi/model.ckpt-300\n",
      "INFO:tensorflow:global_step/sec: 64.0371\n",
      "INFO:tensorflow:loss = 301.32788, step = 300 (1.563 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into blerssi/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-13T13:07:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-13-13:07:50\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.2773734, average_loss = 2.2844741, global_step = 400, loss = 144.37875\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: blerssi/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 59.9166\n",
      "INFO:tensorflow:loss = 296.9566, step = 400 (1.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into blerssi/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-13T13:07:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-13-13:07:52\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.27515823, average_loss = 2.2608829, global_step = 500, loss = 142.8878\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: blerssi/model.ckpt-500\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from blerssi/model.ckpt-500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: blerssi/export/blerssi/temp-b'1586783272'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 294.1643.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.27515823,\n",
       "  'average_loss': 2.2608829,\n",
       "  'loss': 142.8878,\n",
       "  'global_step': 500},\n",
       " [b'blerssi/export/blerssi/1586783272'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Feature columns\n",
    "COLUMNS = list(BLE_RSSI.columns)\n",
    "FEATURES = COLUMNS[2:]\n",
    "LABEL = [COLUMNS[0]]\n",
    "\n",
    "b3001 = tf.feature_column.numeric_column(key='b3001',dtype=tf.float64)\n",
    "b3002 = tf.feature_column.numeric_column(key='b3002',dtype=tf.float64)\n",
    "b3003 = tf.feature_column.numeric_column(key='b3003',dtype=tf.float64)\n",
    "b3004 = tf.feature_column.numeric_column(key='b3004',dtype=tf.float64)\n",
    "b3005 = tf.feature_column.numeric_column(key='b3005',dtype=tf.float64)\n",
    "b3006 = tf.feature_column.numeric_column(key='b3006',dtype=tf.float64)\n",
    "b3007 = tf.feature_column.numeric_column(key='b3007',dtype=tf.float64)\n",
    "b3008 = tf.feature_column.numeric_column(key='b3008',dtype=tf.float64)\n",
    "b3009 = tf.feature_column.numeric_column(key='b3009',dtype=tf.float64)\n",
    "b3010 = tf.feature_column.numeric_column(key='b3010',dtype=tf.float64)\n",
    "b3011 = tf.feature_column.numeric_column(key='b3011',dtype=tf.float64)\n",
    "b3012 = tf.feature_column.numeric_column(key='b3012',dtype=tf.float64)\n",
    "b3013 = tf.feature_column.numeric_column(key='b3013',dtype=tf.float64)\n",
    "feature_columns = [b3001, b3002, b3003, b3004, b3005, b3006, b3007, b3008, b3009, b3010, b3011, b3012, b3013]\n",
    "\n",
    "df_full = pd.read_csv('iBeacon_RSSI_Labeled.csv') #Labeled dataset\n",
    "\n",
    "# Input Data Preprocessing \n",
    "df_full = df_full.drop(['date'],axis = 1)\n",
    "df_full[FEATURES] = (df_full[FEATURES]-df_full[FEATURES].mean())/df_full[FEATURES].std()\n",
    "\n",
    "#Output Data Preprocessing\n",
    "dict = {'O02': 0,'P01': 1,'P02': 2,'R01': 3,'R02': 4,'S01': 5,'S02': 6,'T01': 7,'U02': 8,'U01': 9,'J03': 10,'K03': 11,'L03': 12,'M03': 13,'N03': 14,'O03': 15,'P03': 16,'Q03': 17,'R03': 18,'S03': 19,'T03': 20,'U03': 21,'U04': 22,'T04': 23,'S04': 24,'R04': 25,'Q04': 26,'P04': 27,'O04': 28,'N04': 29,'M04': 30,'L04': 31,'K04': 32,'J04': 33,'I04': 34,'I05': 35,'J05': 36,'K05': 37,'L05': 38,'M05': 39,'N05': 40,'O05': 41,'P05': 42,'Q05': 43,'R05': 44,'S05': 45,'T05': 46,'U05': 47,'S06': 48,'R06': 49,'Q06': 50,'P06': 51,'O06': 52,'N06': 53,'M06': 54,'L06': 55,'K06': 56,'J06': 57,'I06': 58,'F08': 59,'J02': 60,'J07': 61,'I07': 62,'I10': 63,'J10': 64,'D15': 65,'E15': 66,'G15': 67,'J15': 68,'L15': 69,'R15': 70,'T15': 71,'W15': 72,'I08': 73,'I03': 74,'J08': 75,'I01': 76,'I02': 77,'J01': 78,'K01': 79,'K02': 80,'L01': 81,'L02': 82,'M01': 83,'M02': 84,'N01': 85,'N02': 86,'O01': 87,'I09': 88,'D14': 89,'D13': 90,'K07': 91,'K08': 92,'N15': 93,'P15': 94,'I15': 95,'S15': 96,'U15': 97,'V15': 98,'S07': 99,'S08': 100,'L09': 101,'L08': 102,'Q02': 103,'Q01': 104}\n",
    "df_full['location'] = df_full['location'].map(dict)\n",
    "df_train=df_full.sample(frac=0.8,random_state=200)\n",
    "df_valid=df_full.drop(df_train.index)\n",
    "\n",
    "location_counts = BLE_RSSI.location.value_counts()\n",
    "x1 = np.asarray(df_train[FEATURES])\n",
    "y = np.asarray(df_train['location'])\n",
    "\n",
    "\n",
    "def formatFeatures(features):\n",
    "    formattedFeatures = {}\n",
    "    numColumns = features.shape[1]\n",
    "\n",
    "    for i in range(0, numColumns):\n",
    "        formattedFeatures[\"b\"+str(3001+i)] = features[:, i]\n",
    "\n",
    "    return formattedFeatures\n",
    "\n",
    "trainingFeatures = formatFeatures(x1)\n",
    "trainingCategories = y\n",
    "trainingFeatures\n",
    "\n",
    "# Train Input Function\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((trainingFeatures, y))\n",
    "    dataset = dataset.batch(64).repeat(1000)\n",
    "    return dataset\n",
    "\n",
    "# Test Input Function\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((trainingFeatures, y))\n",
    "    return dataset.batch(64).repeat(1000)\n",
    "\n",
    "# Provide list of GPUs should be used to train the model\n",
    "\n",
    "distribution = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "print('Number of devices: {}'.format(distribution.num_replicas_in_sync))\n",
    "\n",
    "# Configuration of  training model\n",
    "\n",
    "config = tf.estimator.RunConfig(train_distribute=distribution, model_dir=TF_MODEL_DIR, save_summary_steps=100, save_checkpoints_steps=100)\n",
    "\n",
    "# Build 3 layer DNN classifier\n",
    "\n",
    "model = tf.estimator.DNNClassifier(hidden_units = [13,65,110],\n",
    "                 feature_columns = feature_columns,\n",
    "                 model_dir = TF_MODEL_DIR,\n",
    "                 n_classes=105, config=config\n",
    "               )\n",
    "\n",
    "export_final = tf.estimator.FinalExporter(TF_EXPORT_DIR, serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, \n",
    "                                    max_steps=TF_TRAIN_STEPS)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,\n",
    "                                  steps=100,\n",
    "                                  exporters=export_final,\n",
    "                                  throttle_secs=1,\n",
    "                                  start_delay_secs=1)\n",
    "\n",
    "# Train and Evaluate the model\n",
    "\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\r\n",
      "kind: \"InferenceService\"\r\n",
      "metadata:\r\n",
      "  name: \"blerssi-model\"\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      tensorflow:\r\n",
      "        storageUri: \"pvc://workspace-multi-train-gpu/blerssi/export/blerssi\""
     ]
    }
   ],
   "source": [
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/nfs1/$pvc/g\" blerssi_kfserving.yaml\n",
    "! cat blerssi_kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving BLE RSSI Model using kubeflow kfserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/blerssi-model created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f blerssi_kfserving.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "blerssi-model   http://blerssi-model.anonymous.example.com/v1/models/blerssi-model   True    100                                5m6s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Wait for inference service READY=\"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data from serving after setting INGRESS_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying INGRESS_IP...\n",
      "* TCP_NODELAY set\n",
      "* Connected to INGRESS_IP  port 31380 (#0)\n",
      "> POST /v1/models/blerssi-model:predict HTTP/1.1\n",
      "> Host: blerssi-model.anonymous.example.com\n",
      "> User-Agent: curl/7.58.0\n",
      "> Accept: */*\n",
      "> Content-Length: 320\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "* upload completely sent off: 320 out of 320 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 4255\n",
      "< content-type: application/json\n",
      "< date: Mon, 13 Apr 2020 13:13:44 GMT\n",
      "< x-envoy-upstream-service-time: 9717\n",
      "< server: istio-envoy\n",
      "< \n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"all_class_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "            \"all_classes\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\"],\n",
      "            \"probabilities\": [0.0183709804, 2.36383821e-05, 2.23993819e-08, 8.15706704e-12, 1.9185287e-11, 1.99616365e-12, 3.75980714e-12, 3.8678321e-11, 1.60911041e-12, 4.10399631e-11, 2.70316809e-13, 0.000117803669, 0.0167393275, 0.00927906949, 0.936479628, 0.000455911, 2.56480241e-08, 2.61017197e-11, 1.2470182e-11, 6.8488229e-11, 2.08906382e-11, 9.42473703e-12, 1.18559904e-12, 2.44046422e-10, 4.81914801e-13, 3.80854072e-12, 1.50288224e-05, 0.000830174715, 0.000204251381, 4.73721484e-05, 6.28046e-07, 4.85589044e-05, 4.31495124e-08, 7.71678728e-12, 5.18019647e-07, 1.89760881e-12, 7.5990465e-16, 9.66344214e-06, 8.52038575e-05, 4.57825167e-11, 1.01435793e-08, 3.09824757e-12, 2.28536212e-09, 1.81019838e-10, 7.4698967e-09, 3.4350051e-12, 1.02297733e-07, 1.13414382e-11, 8.09716e-07, 1.57897819e-08, 2.49682106e-08, 3.33377459e-09, 1.03785229e-08, 5.45643033e-08, 5.37434971e-07, 0.000693765236, 1.56275701e-06, 1.71821313e-08, 5.36267593e-11, 1.45203444e-07, 2.29706543e-09, 0.00807675067, 0.000964959792, 9.29273654e-08, 8.31868263e-08, 1.99092901e-05, 1.14338764e-06, 9.47150552e-11, 3.78541309e-10, 6.14332762e-09, 9.73702e-07, 9.52849188e-11, 2.26311608e-11, 1.08617559e-08, 6.29535862e-06, 2.11969091e-05, 1.25625815e-13, 9.58159063e-09, 8.46151881e-12, 6.34760795e-08, 7.97313333e-14, 0.00576630374, 2.5822991e-10, 0.000822332397, 2.93401e-05, 0.000287981, 0.000422907848, 8.42661496e-09, 7.04184856e-07, 2.88655201e-06, 3.15422244e-06, 0.00012332316, 2.41443613e-05, 3.24649463e-09, 2.99724121e-07, 1.8363856e-09, 5.19265707e-12, 5.53160512e-12, 1.64904635e-11, 1.47022502e-06, 5.98256067e-09, 1.85991703e-05, 4.32700195e-11, 1.62371033e-10, 1.80459403e-09],\n",
      "            \"logits\": [3.07294226, -3.58271337, -10.5443068, -18.4622116, -17.6069527, -19.8698692, -19.2367287, -16.905817, -20.0854149, -16.84655, -21.869257, -1.97656608, 2.97993088, 2.38993144, 7.00429773, -0.623287439, -10.4088745, -17.2990952, -18.037756, -16.3344345, -17.5217953, -18.3177586, -20.3908482, -15.0637369, -21.2910843, -19.2238503, -4.03561497, -0.0239493102, -1.42623401, -2.88755059, -7.21072769, -2.86280727, -9.88866901, -18.5176983, -7.40332699, -19.9205017, -27.743412, -4.47723579, -2.30053878, -16.7371941, -11.3365, -19.4302597, -12.8268156, -15.3624887, -11.6424599, -19.3270779, -9.02545261, -18.1326332, -6.95665646, -10.8939781, -10.4357376, -12.449235, -11.3136015, -9.65396118, -7.36653233, -0.203451663, -6.29913378, -10.8094702, -16.5790482, -8.67520428, -12.8217087, 2.25115967, 0.126500875, -9.1215229, -9.23225117, -3.75439906, -6.61159, -16.0102234, -14.6247702, -11.8379745, -6.77223492, -16.0042248, -17.4417686, -11.2680931, -4.90577221, -3.6917305, -22.6355438, -11.3934965, -18.4255676, -9.50267792, -23.090189, 1.91420126, -15.007246, -0.0334406793, -3.3666296, -1.08269048, -0.698430896, -11.521946, -7.09629965, -5.68552256, -5.59684324, -1.93077743, -3.56153464, -12.4757652, -7.95047808, -13.0455418, -18.9138508, -18.8506184, -17.7583141, -6.36016941, -11.8644915, -3.82246828, -16.7936363, -15.4712124, -13.0630045],\n",
      "            \"class_ids\": [14],\n",
      "            \"classes\": [\"14\"]\n",
      "        }\n",
      "    ]\n",
      "* Connection #0 to host INGRESS_IP  left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -v -H \"Host: blerssi-model.anonymous.example.com\" http://INGRESS_IP:31380/v1/models/blerssi-model:predict -d '{\"signature_name\":\"predict\",\"instances\":[{\"b3001\":[-0.458086] , \"b3002\":[-0.6244] , \"b3003\":[2.354243], \"b3004\":[-0.404581] , \"b3005\":[1.421444] , \"b3006\":[1.767642] , \"b3007\":[2.637829] , \"b3008\":[-0.603085] , \"b3009\":[0.382779] , \"b3010\":[-0.378999] , \"b3011\":[-0.341798] , \"b3012\":[-0.303249] , \"b3013\":[-0.327776]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete kfserving model & Clean up of stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f blerssi_kfserving.yaml\n",
    "!rm -rf /mnt/blerssi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
