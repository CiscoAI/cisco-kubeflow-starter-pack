{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLE RSSI Dataset for Indoor localization using MinIO storage\n",
    "\n",
    "The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Cisco Kubeflow Starter pack repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cisco-kubeflow-starter-pack'...\n",
      "remote: Enumerating objects: 531, done.\u001b[K\n",
      "remote: Counting objects: 100% (531/531), done.\u001b[K\n",
      "remote: Compressing objects: 100% (349/349), done.\u001b[K\n",
      "remote: Total 3807 (delta 161), reused 422 (delta 92), pack-reused 3276\u001b[K\n",
      "Receiving objects: 100% (3807/3807), 13.66 MiB | 11.25 MiB/s, done.\n",
      "Resolving deltas: 100% (1419/1419), done.\n"
     ]
    }
   ],
   "source": [
    "BRANCH_NAME=\"dev\" #Provide git branch name \"master\" or \"dev\"\n",
    "! git clone -b $BRANCH_NAME https://github.com/CiscoAI/cisco-kubeflow-starter-pack.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "numpy\n",
    "seldon-core\n",
    "tornado>=6.0.3\n",
    "kubeflow-tfjob\n",
    "kubeflow-fairing\n",
    "tensorflow==1.14.0\n",
    "kubernetes==10.0.1\n",
    "minio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
      "Collecting seldon-core\n",
      "  Downloading seldon_core-1.1.0-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tornado>=6.0.3\n",
      "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
      "\u001b[K     |████████████████████████████████| 496 kB 134.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kubeflow-tfjob\n",
      "  Downloading kubeflow_tfjob-0.1.3-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 9.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting kubeflow-fairing\n",
      "  Downloading kubeflow_fairing-0.7.3-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 51.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2 MB 10 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kubernetes==10.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (10.0.1)\n",
      "Collecting minio\n",
      "  Downloading minio-5.0.10-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2019.3)\n",
      "Collecting Flask<2.0.0\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: prometheus-client<0.8.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from seldon-core->-r requirements.txt (line 3)) (0.7.1)\n",
      "Collecting jaeger-client<4.2.0,>=4.1.0\n",
      "  Downloading jaeger-client-4.1.0.tar.gz (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from seldon-core->-r requirements.txt (line 3)) (2.22.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.6/dist-packages (from seldon-core->-r requirements.txt (line 3)) (3.11.2)\n",
      "Requirement already satisfied: grpcio<2.0.0 in /usr/local/lib/python3.6/dist-packages (from seldon-core->-r requirements.txt (line 3)) (1.26.0)\n",
      "Collecting redis<4.0.0\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opentracing<2.3.0,>=2.2.0\n",
      "  Downloading opentracing-2.2.0.tar.gz (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask-OpenTracing<1.2.0,>=1.1.0\n",
      "  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)\n",
      "Collecting flatbuffers<2.0.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting Flask-cors<4.0.0\n",
      "  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-storage-blob<3.0.0,>=2.0.1\n",
      "  Downloading azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn<20.1.0,>=19.9.0\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from seldon-core->-r requirements.txt (line 3)) (45.1.0)\n",
      "Collecting pyaml<20.0.0\n",
      "  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting grpcio-opentracing<1.2.0,>=1.1.4\n",
      "  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from kubeflow-tfjob->-r requirements.txt (line 5)) (1.25.8)\n",
      "Collecting table-logger>=0.3.5\n",
      "  Downloading table_logger-0.3.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.6/dist-packages (from kubeflow-tfjob->-r requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kubeflow-tfjob->-r requirements.txt (line 5)) (1.11.0)\n",
      "Requirement already satisfied: notebook>=5.6.0 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (6.0.3)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (1.7.11)\n",
      "Collecting kubeflow-pytorchjob>=0.1.1\n",
      "  Downloading kubeflow_pytorchjob-0.1.3-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk>=2.6.0\n",
      "  Downloading ibm-cos-sdk-2.6.3.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-storage>=9.0.0\n",
      "  Downloading azure_mgmt_storage-10.0.0-py2.py3-none-any.whl (532 kB)\n",
      "\u001b[K     |████████████████████████████████| 532 kB 48.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting boto3>=1.9.0\n",
      "  Downloading boto3-1.14.1-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kfserving>=0.2.1.1\n",
      "  Downloading kfserving-0.3.0.1-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-storage>=1.13.2 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (1.25.0)\n",
      "Requirement already satisfied: google-auth>=1.6.2 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (1.11.0)\n",
      "Collecting google-cloud-logging>=1.13.0\n",
      "  Downloading google_cloud_logging-1.15.0-py2.py3-none-any.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (0.18.2)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (4.1.3)\n",
      "Requirement already satisfied: docker>=3.4.1 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (4.1.0)\n",
      "Requirement already satisfied: cloudpickle>=0.8 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (1.2.2)\n",
      "Collecting azure-storage-file>=2.1.0\n",
      "  Downloading azure_storage_file-2.1.0-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: httplib2>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from kubeflow-fairing->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (1.11.2)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 33.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 54.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (0.1.8)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 7)) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes==10.0.1->-r requirements.txt (line 8)) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes==10.0.1->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: pyyaml>=3.12 in /usr/local/lib/python3.6/dist-packages (from kubernetes==10.0.1->-r requirements.txt (line 8)) (5.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting configparser\n",
      "  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask<2.0.0->seldon-core->-r requirements.txt (line 3)) (0.16.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask<2.0.0->seldon-core->-r requirements.txt (line 3)) (2.11.0)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting threadloop<2,>=1\n",
      "  Downloading threadloop-1.0.2.tar.gz (4.9 kB)\n",
      "Collecting thrift\n",
      "  Downloading thrift-0.13.0.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 23.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->seldon-core->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0->seldon-core->-r requirements.txt (line 3)) (2.6)\n",
      "Collecting azure-storage-common~=2.1\n",
      "  Downloading azure_storage_common-2.1.0-py2.py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-common>=1.1.5\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (4.3.3)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (5.0.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (18.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.8.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (5.6.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (5.1.4)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (4.6.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (5.3.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->kubeflow-fairing->-r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->kubeflow-fairing->-r requirements.txt (line 6)) (0.0.3)\n",
      "Collecting ibm-cos-sdk-core==2.6.3\n",
      "  Downloading ibm-cos-sdk-core-2.6.3.tar.gz (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 37.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.6.3\n",
      "  Downloading ibm-cos-sdk-s3transfer-2.6.3.tar.gz (218 kB)\n",
      "\u001b[K     |████████████████████████████████| 218 kB 49.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.6.16-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting msrestazure<2.0.0,>=0.4.32\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.18.0,>=1.17.1\n",
      "  Downloading botocore-1.17.1.tar.gz (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 33.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting argparse>=1.4.0\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting adal>=1.2.2\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 9.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.2->kubeflow-fairing->-r requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.2->kubeflow-fairing->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.2->kubeflow-fairing->-r requirements.txt (line 6)) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.2->kubeflow-fairing->-r requirements.txt (line 6)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.2->kubeflow-fairing->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-logging>=1.13.0->kubeflow-fairing->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.4.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0->-r requirements.txt (line 7)) (2.10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes==10.0.1->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask<2.0.0->seldon-core->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core->-r requirements.txt (line 3)) (2.1.4)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (4.4.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (2.5.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.4.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (7.11.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 54.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting PyJWT>=1.0.0\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-logging>=1.13.0->kubeflow-fairing->-r requirements.txt (line 6)) (1.51.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.15.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.1.8)\n",
      "Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=5.6.0->kubeflow-fairing->-r requirements.txt (line 6)) (0.6.0)\n",
      "Building wheels for collected packages: tornado, jaeger-client, opentracing, Flask-OpenTracing, ibm-cos-sdk, retrying, threadloop, thrift, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, botocore\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-6.0.4-cp36-cp36m-linux_x86_64.whl size=429297 sha256=21fc75ed2f3c680333a5fd5ab196141e08fdd00be1245461e489f4b54f31c996\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/37/a7/db/2d592e44029ef817f3ef63ea991db34191cebaef087a96f505\n",
      "  Building wheel for jaeger-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jaeger-client: filename=jaeger_client-4.1.0-py3-none-any.whl size=65467 sha256=d825f79dfc8c6fdb450df3cc3c0dec04df676ed13a01720bf76b7298f3a370d3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e9/9b/8c/503d0cc13b39a551c054515683ba1d15b40324c863dc442e66\n",
      "  Building wheel for opentracing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opentracing: filename=opentracing-2.2.0-py3-none-any.whl size=49672 sha256=0baca69c1ab1f4eebbdf7ecc319f2dc732cf3c0828892eb8fac09a848bd9f421\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/39/40/44/8bace79f4514e99786236c31f1df8d1b814ff02c1e08b1d697\n",
      "  Building wheel for Flask-OpenTracing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=11453 sha256=b5540b8cf10319024c0f292b9a58fb52a08c4bd7643b5e826a899a63cbf36bea\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ad/4b/2d/24ff0da0a0b53c7c77ce59b843bcceaf644c88703241e59615\n",
      "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.6.3-py2.py3-none-any.whl size=71872 sha256=98a0e95acbb76a670920685d31dc0571b413dc6a8d386f314c5dd31b1d14cb9d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ef/58/27/fd3a79b755c68ac4df18e6549349da954487ec9bc0c5afa3bd\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=9530 sha256=864a12709deee3ca518ad7b7c3b81552261f79623a07d3aa8ac74a57ca24307b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ac/cb/8a/b27bf6323e2f4c462dcbf77d70b7c5e7868a7fbe12871770cf\n",
      "  Building wheel for threadloop (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=4261 sha256=c5dd0886144238cb203712f7b6f8a8a4eea37f7b8fae53992b8dd5e308acce4c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/02/54/65/9f87de48fe8fcaaee30f279973d946ad55f9df56b93b3e78da\n",
      "  Building wheel for thrift (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=346206 sha256=ee20c5dd7801ac29259222d418a4c2b596274ded6d858a98228289ac6930ce4c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d\n",
      "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.6.3-py2.py3-none-any.whl size=498466 sha256=5d108a6b5149b4224546eb4184218878b340937699bfd54f1f9946036bd06bac\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e2/38/49/5b0cff6e6f8c934e5e13e486f14a71a4280dac28ac9d2c283c\n",
      "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.6.3-py2.py3-none-any.whl size=85447 sha256=6f42e77d1adac041d7eb0d02276f7213f0b59d9e6d931b89f28e90a607d21be8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/78/13/e4/136b34f8b794eb51602253272adf64642b4d3f1d137be2b5fe\n",
      "  Building wheel for botocore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for botocore: filename=botocore-1.17.1-py2.py3-none-any.whl size=6260185 sha256=1801ee65a745989e3d0596d2e5e1ad5ff4f5435f94ae5eea87fb3a5817180b2a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/71/06/c9/0dbe01a8fc0ce1066bb6df322900e9e9390f819f4fef747767\n",
      "Successfully built tornado jaeger-client opentracing Flask-OpenTracing ibm-cos-sdk retrying threadloop thrift ibm-cos-sdk-core ibm-cos-sdk-s3transfer botocore\n",
      "\u001b[31mERROR: fairing 0.5 has requirement tornado<6.0.0,>=5.1.1, but you'll have tornado 6.0.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jaeger-client 4.1.0 has requirement tornado<6,>=4.3, but you'll have tornado 6.0.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kubeflow-fairing 0.7.3 has requirement grpcio>=1.27.2, but you'll have grpcio 1.26.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kubeflow-fairing 0.7.3 has requirement python-dateutil<=2.8.0,>=2.1, but you'll have python-dateutil 2.8.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kubeflow-fairing 0.7.3 has requirement urllib3==1.24.2, but you'll have urllib3 1.25.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pandas, click, itsdangerous, Flask, tornado, threadloop, thrift, opentracing, jaeger-client, redis, Flask-OpenTracing, flatbuffers, Flask-cors, azure-common, azure-storage-common, azure-storage-blob, gunicorn, pyaml, grpcio-opentracing, configparser, minio, seldon-core, table-logger, kubeflow-tfjob, kubeflow-pytorchjob, jmespath, docutils, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, isodate, msrest, PyJWT, adal, msrestazure, azure-mgmt-storage, retrying, botocore, s3transfer, boto3, argparse, kfserving, google-cloud-logging, azure-storage-file, kubeflow-fairing, tensorboard, tensorflow-estimator, tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script flask is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script gunicorn is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts seldon-core-api-tester, seldon-core-microservice, seldon-core-microservice-tester and seldon-core-tester are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script pyjwt is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 PyJWT-1.7.1 adal-1.2.4 argparse-1.4.0 azure-common-1.1.25 azure-mgmt-storage-10.0.0 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 azure-storage-file-2.1.0 boto3-1.14.1 botocore-1.17.1 click-7.1.2 configparser-5.0.0 docutils-0.15.2 flatbuffers-1.12 google-cloud-logging-1.15.0 grpcio-opentracing-1.1.4 gunicorn-20.0.4 ibm-cos-sdk-2.6.3 ibm-cos-sdk-core-2.6.3 ibm-cos-sdk-s3transfer-2.6.3 isodate-0.6.0 itsdangerous-1.1.0 jaeger-client-4.1.0 jmespath-0.10.0 kfserving-0.3.0.1 kubeflow-fairing-0.7.3 kubeflow-pytorchjob-0.1.3 kubeflow-tfjob-0.1.3 minio-5.0.10 msrest-0.6.16 msrestazure-0.6.3 opentracing-2.2.0 pandas-1.0.4 pyaml-19.12.0 redis-3.5.3 retrying-1.3.3 s3transfer-0.3.3 seldon-core-1.1.0 table-logger-0.3.6 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 threadloop-1.0.2 thrift-0.13.0 tornado-6.0.4\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Notebook kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "import yaml\n",
    "from minio import Minio\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes.client import rest as k8s_rest\n",
    "from kubernetes import config as k8s_config\n",
    "from kubernetes.client.rest import ApiException\n",
    "from kubeflow.fairing.cloud.k8s import MinioUploader\n",
    "from kubeflow.fairing.builders.cluster.minio_context import MinioContextSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create minio secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing minio-secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile minio-secret.yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: miniosecret\n",
    "  annotations:\n",
    "     serving.kubeflow.org/s3-endpoint: minio-service.kubeflow:9000 # replace with your s3 endpoint\n",
    "     serving.kubeflow.org/s3-usehttps: \"0\" # by default 1, for testing with minio you need to set to 0\n",
    "type: Opaque\n",
    "stringData:\n",
    "  awsAccessKeyID: minio\n",
    "  awsSecretAccessKey: minio123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/miniosecret created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f minio-secret.yaml -n anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miniosecret                  Opaque                                2      0s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get secrets -n anonymous | grep miniosecret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a minio serviceaccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing minio-serviceaccount.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile minio-serviceaccount.yaml\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: minio-sa\n",
    "secrets:\n",
    "- name: miniosecret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/minio-sa created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f minio-serviceaccount.yaml -n anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minio-sa         2         1s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get serviceaccount -n anonymous | grep minio-sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to minio service using credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://10.106.203.39:9000\n"
     ]
    }
   ],
   "source": [
    "k8s_config.load_incluster_config()\n",
    "api_client = k8s_client.CoreV1Api()\n",
    "minio_service_endpoint = None\n",
    "\n",
    "try:\n",
    "    minio_service_endpoint = api_client.read_namespaced_service(name='minio-service', namespace='kubeflow').spec.cluster_ip\n",
    "except ApiException as e:\n",
    "    if e.status == 403:\n",
    "        logging.warning(f\"The service account doesn't have sufficient privileges \"\n",
    "                      f\"to get the kubeflow minio-service. \"\n",
    "                      f\"You will have to manually enter the minio cluster-ip. \"\n",
    "                      f\"To make this function work ask someone with cluster \"\n",
    "                      f\"priveleges to create an appropriate \"\n",
    "                      f\"clusterrolebinding by running a command.\\n\"\n",
    "                      f\"kubectl create --namespace=kubeflow rolebinding \"\n",
    "                       \"--clusterrole=kubeflow-view \"\n",
    "                       \"--serviceaccount=${NAMESPACE}:default-editor \"\n",
    "                       \"${NAMESPACE}-minio-view\")\n",
    "        logging.error(\"API access denied with reason: {e.reason}\")\n",
    "\n",
    "s3_endpoint = minio_service_endpoint\n",
    "s3_endPoint = s3_endpoint+\":9000\"\n",
    "minio_endpoint = \"http://\"+s3_endPoint\n",
    "minio_username = \"minio\"\n",
    "minio_key = \"minio123\"\n",
    "minio_region = \"us-east-1\"\n",
    "print(minio_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MinIO uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_uploader = MinioUploader(endpoint_url=minio_endpoint, minio_secret=minio_username, minio_secret_key=minio_key, region_name=minio_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a MinIO bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200612 05:04:27 <ipython-input-10-e492695c48ef>:3] Bucket minioblerssi created or already exists\n"
     ]
    }
   ],
   "source": [
    "minio_bucket = \"minioblerssi\"\n",
    "minio_uploader.create_bucket(minio_bucket)\n",
    "logging.info(f\"Bucket {minio_bucket} created or already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare variables for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'cisco-kubeflow-starter-pack/apps/networking/ble-localization/onprem/data/'\n",
    "BLE_RSSI = pd.read_csv(os.path.join(path, 'iBeacon_RSSI_Labeled.csv')) #Labeled dataset\n",
    "                       \n",
    "# Configure model options\n",
    "TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/tmp/data/\")\n",
    "TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"/tmp/blerssi/\")\n",
    "TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"blerssi/\")\n",
    "TF_MODEL_TYPE = os.getenv(\"TF_MODEL_TYPE\", \"DNN\")\n",
    "TF_TRAIN_STEPS = int(os.getenv(\"TF_TRAIN_STEPS\", 5000))\n",
    "TF_BATCH_SIZE = int(os.getenv(\"TF_BATCH_SIZE\", 50))\n",
    "TF_LEARNING_RATE = float(os.getenv(\"TF_LEARNING_RATE\", 0.00001))\n",
    "\n",
    "\n",
    "# Feature columns\n",
    "COLUMNS = list(BLE_RSSI.columns)\n",
    "FEATURES = COLUMNS[2:]\n",
    "LABEL = [COLUMNS[0]]\n",
    "\n",
    "INPUT_FEATURE = 'x'\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLERSSI Input Dataset\n",
    "\n",
    "### Attribute Information\n",
    "\n",
    "    location: The location of receiving RSSIs from ibeacons b3001 to b3013; \n",
    "              symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1).\n",
    "    date: Datetime in the format of ‘d-m-yyyy hh:mm:ss’\n",
    "    b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>b3001</th>\n",
       "      <th>b3002</th>\n",
       "      <th>b3003</th>\n",
       "      <th>b3004</th>\n",
       "      <th>b3005</th>\n",
       "      <th>b3006</th>\n",
       "      <th>b3007</th>\n",
       "      <th>b3008</th>\n",
       "      <th>b3009</th>\n",
       "      <th>b3010</th>\n",
       "      <th>b3011</th>\n",
       "      <th>b3012</th>\n",
       "      <th>b3013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O02</td>\n",
       "      <td>10-18-2016 11:15:21</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-78</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:19</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-78</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:17</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:15</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:13</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:11</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-82</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P01</td>\n",
       "      <td>10-18-2016 11:15:09</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-80</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-77</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P02</td>\n",
       "      <td>10-18-2016 11:15:07</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-86</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R01</td>\n",
       "      <td>10-18-2016 11:15:05</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-75</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R01</td>\n",
       "      <td>10-18-2016 11:15:03</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-75</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                 date  b3001  b3002  b3003  b3004  b3005  b3006  \\\n",
       "0      O02  10-18-2016 11:15:21   -200   -200   -200   -200   -200    -78   \n",
       "1      P01  10-18-2016 11:15:19   -200   -200   -200   -200   -200    -78   \n",
       "2      P01  10-18-2016 11:15:17   -200   -200   -200   -200   -200    -77   \n",
       "3      P01  10-18-2016 11:15:15   -200   -200   -200   -200   -200    -77   \n",
       "4      P01  10-18-2016 11:15:13   -200   -200   -200   -200   -200    -77   \n",
       "5      P01  10-18-2016 11:15:11   -200   -200    -82   -200   -200   -200   \n",
       "6      P01  10-18-2016 11:15:09   -200   -200    -80   -200   -200    -77   \n",
       "7      P02  10-18-2016 11:15:07   -200   -200    -86   -200   -200   -200   \n",
       "8      R01  10-18-2016 11:15:05   -200   -200   -200    -75   -200   -200   \n",
       "9      R01  10-18-2016 11:15:03   -200   -200   -200    -75   -200   -200   \n",
       "\n",
       "   b3007  b3008  b3009  b3010  b3011  b3012  b3013  \n",
       "0   -200   -200   -200   -200   -200   -200   -200  \n",
       "1   -200   -200   -200   -200   -200   -200   -200  \n",
       "2   -200   -200   -200   -200   -200   -200   -200  \n",
       "3   -200   -200   -200   -200   -200   -200   -200  \n",
       "4   -200   -200   -200   -200   -200   -200   -200  \n",
       "5   -200   -200   -200   -200   -200   -200   -200  \n",
       "6   -200   -200   -200   -200   -200   -200   -200  \n",
       "7   -200   -200   -200   -200   -200   -200   -200  \n",
       "8   -200   -200   -200   -200   -200   -200   -200  \n",
       "9   -200   -200   -200   -200   -200   -200   -200  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLE_RSSI.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Serving Input Receiver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"\n",
    "    This is used to define inputs to serve the model.\n",
    "    :return: ServingInputReciever\n",
    "    \"\"\"\n",
    "    receiver_tensors = {\n",
    "        'b3001': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3002': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3003': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3004': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3005': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3006': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3007': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3008': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3009': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3010': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3011': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3012': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'b3013': tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    }\n",
    "\n",
    "    # Convert give inputs to adjust to the model.\n",
    "    features = {\n",
    "         INPUT_FEATURE: tf.concat([\n",
    "            receiver_tensors['b3001'],\n",
    "            receiver_tensors['b3002'],\n",
    "            receiver_tensors['b3003'],\n",
    "            receiver_tensors['b3004'],\n",
    "            receiver_tensors['b3005'],\n",
    "            receiver_tensors['b3006'],\n",
    "            receiver_tensors['b3007'],\n",
    "            receiver_tensors['b3008'],\n",
    "            receiver_tensors['b3009'],\n",
    "            receiver_tensors['b3010'],\n",
    "            receiver_tensors['b3011'],\n",
    "            receiver_tensors['b3012'],\n",
    "            receiver_tensors['b3013'],\n",
    "\n",
    "        ], axis=1)\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(receiver_tensors=receiver_tensors,\n",
    "                                                    features=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save BLE RSSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/blerssi/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd3d1980390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.015490 140550116915008 estimator.py:209] Using config: {'_model_dir': '/tmp/blerssi/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd3d1980390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.018362 140550116915008 estimator_training.py:186] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.020625 140550116915008 training.py:612] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.022089 140550116915008 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.041648 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.055006 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.057676 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.066189 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.079930 140550116915008 deprecation.py:506] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.827579 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:41.924638 140550116915008 deprecation.py:506] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.962111 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:41.964350 140550116915008 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:42.018773 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.115209 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.182463 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.188366 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:42.203000 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.389777 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 55.232437, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.616251 140550116915008 basic_session_run_hooks.py:262] loss = 55.232437, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 492.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.818678 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 492.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 46.684113, step = 101 (0.206 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.822290 140550116915008 basic_session_run_hooks.py:260] loss = 46.684113, step = 101 (0.206 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 601.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.985064 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 601.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.680935, step = 201 (0.168 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:42.989972 140550116915008 basic_session_run_hooks.py:260] loss = 42.680935, step = 201 (0.168 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 606.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.149871 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 606.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.145786, step = 301 (0.163 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.153301 140550116915008 basic_session_run_hooks.py:260] loss = 45.145786, step = 301 (0.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 620.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.310909 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 620.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.738262, step = 401 (0.161 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.314618 140550116915008 basic_session_run_hooks.py:260] loss = 36.738262, step = 401 (0.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 594.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.479227 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 594.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 39.400314, step = 501 (0.169 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.483313 140550116915008 basic_session_run_hooks.py:260] loss = 39.400314, step = 501 (0.169 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 598.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.646330 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 598.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 35.916065, step = 601 (0.168 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.650921 140550116915008 basic_session_run_hooks.py:260] loss = 35.916065, step = 601 (0.168 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 621.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.807133 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 621.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.96006, step = 701 (0.160 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.811187 140550116915008 basic_session_run_hooks.py:260] loss = 32.96006, step = 701 (0.160 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 585.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.977802 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 585.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.887512, step = 801 (0.171 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:43.981844 140550116915008 basic_session_run_hooks.py:260] loss = 31.887512, step = 801 (0.171 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 610.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.141719 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 610.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 33.172104, step = 901 (0.164 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.146069 140550116915008 basic_session_run_hooks.py:260] loss = 33.172104, step = 901 (0.164 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.312354 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.387656 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.769822 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-12T05:04:44Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.785498 140550116915008 evaluation.py:255] Starting evaluation at 2020-06-12T05:04:44Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.866822 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:44.869099 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.872031 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.902552 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.913222 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:44.980987 140550116915008 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-12-05:04:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.017990 140550116915008 evaluation.py:275] Finished evaluation at 2020-06-12-05:04:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.16666667, average_loss = 2.693391, global_step = 1000, loss = 32.320694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.020505 140550116915008 estimator.py:2039] Saving dict for global step 1000: accuracy = 0.16666667, average_loss = 2.693391, global_step = 1000, loss = 32.320694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/blerssi/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.083891 140550116915008 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: /tmp/blerssi/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 105.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.088619 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 105.594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.595047, step = 1001 (0.945 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.090998 140550116915008 basic_session_run_hooks.py:260] loss = 36.595047, step = 1001 (0.945 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 656.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.240994 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 656.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.349031, step = 1101 (0.153 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.244333 140550116915008 basic_session_run_hooks.py:260] loss = 29.349031, step = 1101 (0.153 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 665.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.391355 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 665.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.635857, step = 1201 (0.150 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.394765 140550116915008 basic_session_run_hooks.py:260] loss = 32.635857, step = 1201 (0.150 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 645.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.546199 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 645.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.479633, step = 1301 (0.155 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.549864 140550116915008 basic_session_run_hooks.py:260] loss = 38.479633, step = 1301 (0.155 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 612.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.709465 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 612.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.415203, step = 1401 (0.163 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.712946 140550116915008 basic_session_run_hooks.py:260] loss = 31.415203, step = 1401 (0.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 641.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.865368 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 641.419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.585121, step = 1501 (0.156 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:45.868943 140550116915008 basic_session_run_hooks.py:260] loss = 31.585121, step = 1501 (0.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 678.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.012708 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 678.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 37.519608, step = 1601 (0.147 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.016212 140550116915008 basic_session_run_hooks.py:260] loss = 37.519608, step = 1601 (0.147 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 611.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.176425 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 611.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.776356, step = 1701 (0.165 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.180885 140550116915008 basic_session_run_hooks.py:260] loss = 31.776356, step = 1701 (0.165 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 647.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.330625 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 647.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 33.624756, step = 1801 (0.153 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.334240 140550116915008 basic_session_run_hooks.py:260] loss = 33.624756, step = 1801 (0.153 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 582.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.502272 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 582.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.78556, step = 1901 (0.172 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.506011 140550116915008 basic_session_run_hooks.py:260] loss = 32.78556, step = 1901 (0.172 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.669318 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.742418 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.956497 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-12T05:04:46Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:46.972365 140550116915008 evaluation.py:255] Starting evaluation at 2020-06-12T05:04:46Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.187937 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.191433 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.223840 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.234123 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.320863 140550116915008 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-12-05:04:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.351669 140550116915008 evaluation.py:275] Finished evaluation at 2020-06-12-05:04:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.25, average_loss = 2.4015324, global_step = 2000, loss = 28.81839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.353872 140550116915008 estimator.py:2039] Saving dict for global step 2000: accuracy = 0.25, average_loss = 2.4015324, global_step = 2000, loss = 28.81839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/blerssi/model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.357390 140550116915008 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2000: /tmp/blerssi/model.ckpt-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.364318 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.764818, step = 2001 (0.861 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.366883 140550116915008 basic_session_run_hooks.py:260] loss = 29.764818, step = 2001 (0.861 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 615.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.526772 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 615.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.704826, step = 2101 (0.163 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.530365 140550116915008 basic_session_run_hooks.py:260] loss = 32.704826, step = 2101 (0.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 612.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.689917 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 612.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.451412, step = 2201 (0.163 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.693153 140550116915008 basic_session_run_hooks.py:260] loss = 31.451412, step = 2201 (0.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 638.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.846588 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 638.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.57327, step = 2301 (0.157 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:47.850287 140550116915008 basic_session_run_hooks.py:260] loss = 29.57327, step = 2301 (0.157 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 640.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.002666 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 640.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.522358, step = 2401 (0.156 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.006210 140550116915008 basic_session_run_hooks.py:260] loss = 26.522358, step = 2401 (0.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 619.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.164083 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 619.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 28.608887, step = 2501 (0.162 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.167835 140550116915008 basic_session_run_hooks.py:260] loss = 28.608887, step = 2501 (0.162 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 585.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.334951 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 585.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.854666, step = 2601 (0.171 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.338576 140550116915008 basic_session_run_hooks.py:260] loss = 27.854666, step = 2601 (0.171 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 551.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.516173 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 551.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.586784, step = 2701 (0.181 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.520032 140550116915008 basic_session_run_hooks.py:260] loss = 32.586784, step = 2701 (0.181 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 540.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.701271 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 540.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.99612, step = 2801 (0.186 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.705847 140550116915008 basic_session_run_hooks.py:260] loss = 29.99612, step = 2801 (0.186 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 601.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.867568 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 601.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.221558, step = 2901 (0.165 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:48.871162 140550116915008 basic_session_run_hooks.py:260] loss = 29.221558, step = 2901 (0.165 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.018068 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.090513 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.295481 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-12T05:04:49Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.311262 140550116915008 evaluation.py:255] Starting evaluation at 2020-06-12T05:04:49Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.394888 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.398674 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.429307 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.439292 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.544956 140550116915008 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-12-05:04:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.574305 140550116915008 evaluation.py:275] Finished evaluation at 2020-06-12-05:04:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.41666666, average_loss = 1.9658886, global_step = 3000, loss = 23.590664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.575681 140550116915008 estimator.py:2039] Saving dict for global step 3000: accuracy = 0.41666666, average_loss = 1.9658886, global_step = 3000, loss = 23.590664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /tmp/blerssi/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.577359 140550116915008 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3000: /tmp/blerssi/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 139.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.585468 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 139.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.042995, step = 3001 (0.717 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.588112 140550116915008 basic_session_run_hooks.py:260] loss = 30.042995, step = 3001 (0.717 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 663.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.736119 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 663.952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.531578, step = 3101 (0.152 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.739672 140550116915008 basic_session_run_hooks.py:260] loss = 29.531578, step = 3101 (0.152 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 568.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.911905 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 568.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.35074, step = 3201 (0.176 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:49.915382 140550116915008 basic_session_run_hooks.py:260] loss = 32.35074, step = 3201 (0.176 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 561.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.089922 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 561.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.168362, step = 3301 (0.178 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.093434 140550116915008 basic_session_run_hooks.py:260] loss = 31.168362, step = 3301 (0.178 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 565.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.266751 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 565.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.39294, step = 3401 (0.177 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.270220 140550116915008 basic_session_run_hooks.py:260] loss = 30.39294, step = 3401 (0.177 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 606.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.431587 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 606.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.76358, step = 3501 (0.165 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.435334 140550116915008 basic_session_run_hooks.py:260] loss = 32.76358, step = 3501 (0.165 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 569.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.607023 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 569.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 28.986237, step = 3601 (0.175 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.610465 140550116915008 basic_session_run_hooks.py:260] loss = 28.986237, step = 3601 (0.175 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 599.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.773738 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 599.926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 25.108418, step = 3701 (0.167 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.777251 140550116915008 basic_session_run_hooks.py:260] loss = 25.108418, step = 3701 (0.167 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 579.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.946252 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 579.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 25.700266, step = 3801 (0.173 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:50.949898 140550116915008 basic_session_run_hooks.py:260] loss = 25.700266, step = 3801 (0.173 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 554.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.126458 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 554.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.412584, step = 3901 (0.179 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.129299 140550116915008 basic_session_run_hooks.py:260] loss = 26.412584, step = 3901 (0.179 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.285470 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.352345 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.697430 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-12T05:04:51Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.713275 140550116915008 evaluation.py:255] Starting evaluation at 2020-06-12T05:04:51Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.796367 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.799975 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.831000 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.852568 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.929846 140550116915008 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-12-05:04:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.955621 140550116915008 evaluation.py:275] Finished evaluation at 2020-06-12-05:04:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.33333334, average_loss = 2.3715503, global_step = 4000, loss = 28.458605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.957556 140550116915008 estimator.py:2039] Saving dict for global step 4000: accuracy = 0.33333334, average_loss = 2.3715503, global_step = 4000, loss = 28.458605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/blerssi/model.ckpt-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.960282 140550116915008 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4000: /tmp/blerssi/model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 119.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.966046 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 119.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 28.638882, step = 4001 (0.839 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:51.968780 140550116915008 basic_session_run_hooks.py:260] loss = 28.638882, step = 4001 (0.839 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 642.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.122014 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 642.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.510252, step = 4101 (0.160 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.128337 140550116915008 basic_session_run_hooks.py:260] loss = 27.510252, step = 4101 (0.160 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 609.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.285717 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 609.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 28.6623, step = 4201 (0.161 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.289156 140550116915008 basic_session_run_hooks.py:260] loss = 28.6623, step = 4201 (0.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 644.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.440747 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 644.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.550396, step = 4301 (0.154 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.443197 140550116915008 basic_session_run_hooks.py:260] loss = 29.550396, step = 4301 (0.154 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 659.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.592308 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 659.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.20568, step = 4401 (0.153 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.595903 140550116915008 basic_session_run_hooks.py:260] loss = 29.20568, step = 4401 (0.153 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 642.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.747985 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 642.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.247528, step = 4501 (0.156 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.751553 140550116915008 basic_session_run_hooks.py:260] loss = 29.247528, step = 4501 (0.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 701.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.890532 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 701.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.32248, step = 4601 (0.141 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:52.892999 140550116915008 basic_session_run_hooks.py:260] loss = 30.32248, step = 4601 (0.141 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 642.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.046222 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 642.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.41931, step = 4701 (0.156 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.049397 140550116915008 basic_session_run_hooks.py:260] loss = 27.41931, step = 4701 (0.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 636.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.203361 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 636.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 33.191628, step = 4801 (0.158 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.207427 140550116915008 basic_session_run_hooks.py:260] loss = 33.191628, step = 4801 (0.158 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 630.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.361701 140550116915008 basic_session_run_hooks.py:692] global_step/sec: 630.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 23.91732, step = 4901 (0.158 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.365797 140550116915008 basic_session_run_hooks.py:260] loss = 23.91732, step = 4901 (0.158 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.523658 140550116915008 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into /tmp/blerssi/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:53.539966 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.605485 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.807874 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-12T05:04:53Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.823287 140550116915008 evaluation.py:255] Starting evaluation at 2020-06-12T05:04:53Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.905128 140550116915008 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.908633 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.940441 140550116915008 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:53.951261 140550116915008 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.043370 140550116915008 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-12-05:04:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.073162 140550116915008 evaluation.py:275] Finished evaluation at 2020-06-12-05:04:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.33333334, average_loss = 2.562431, global_step = 5000, loss = 30.749174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.075331 140550116915008 estimator.py:2039] Saving dict for global step 5000: accuracy = 0.33333334, average_loss = 2.562431, global_step = 5000, loss = 30.749174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.078219 140550116915008 estimator.py:2099] Saving 'checkpoint_path' summary for global step 5000: /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Performing the final export in the end of training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.081881 140550116915008 exporter.py:410] Performing the final export in the end of training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.107509 140550116915008 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.429591 140550116915008 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:54.432825 140550116915008 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.435048 140550116915008 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.436940 140550116915008 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.438227 140550116915008 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.439468 140550116915008 export_utils.py:170] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.440650 140550116915008 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.442141 140550116915008 export_utils.py:173] Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?, 1) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?, 1) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.443436 140550116915008 export_utils.py:176] 'serving_default' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?, 1) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?, 1) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?, 1) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?, 1) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.444688 140550116915008 export_utils.py:176] 'classification' : Classification input must be a single string Tensor; got {'b3001': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'b3002': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'b3003': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'b3004': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'b3005': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'b3006': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'b3007': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'b3008': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'b3009': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'b3010': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>, 'b3011': <tf.Tensor 'Placeholder_10:0' shape=(?, 1) dtype=float32>, 'b3012': <tf.Tensor 'Placeholder_11:0' shape=(?, 1) dtype=float32>, 'b3013': <tf.Tensor 'Placeholder_12:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0612 05:04:54.445786 140550116915008 export_utils.py:182] Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.498294 140550116915008 saver.py:1280] Restoring parameters from /tmp/blerssi/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.516184 140550116915008 builder_impl.py:661] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.517606 140550116915008 builder_impl.py:456] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /tmp/blerssi/export/blerssi/temp-b'1591938294'/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.572437 140550116915008 builder_impl.py:421] SavedModel written to: /tmp/blerssi/export/blerssi/temp-b'1591938294'/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 33.19045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0612 05:04:54.649502 140550116915008 estimator.py:368] Loss for final step: 33.19045.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_args):\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  df_full = pd.read_csv(os.path.join(path,'iBeacon_RSSI_Labeled.csv')) #Labeled dataset\n",
    "\n",
    "  # Input Data Preprocessing \n",
    "  df_full = df_full.drop(['date'],axis=1)\n",
    "  df_full[FEATURES] = (df_full[FEATURES])/(-200)#-df_full[FEATURES].mean())/df_full[FEATURES].std()\n",
    "\n",
    "  #Output Data Preprocessing\n",
    "  dict = {'O02': 0,'P01': 1,'P02': 2,'R01': 3,'R02': 4,'S01': 5,'S02': 6,'T01': 7,'U02': 8,'U01': 9,'J03': 10,'K03': 11,'L03': 12,'M03': 13,'N03': 14,'O03': 15,'P03': 16,'Q03': 17,'R03': 18,'S03': 19,'T03': 20,'U03': 21,'U04': 22,'T04': 23,'S04': 24,'R04': 25,'Q04': 26,'P04': 27,'O04': 28,'N04': 29,'M04': 30,'L04': 31,'K04': 32,'J04': 33,'I04': 34,'I05': 35,'J05': 36,'K05': 37,'L05': 38,'M05': 39,'N05': 40,'O05': 41,'P05': 42,'Q05': 43,'R05': 44,'S05': 45,'T05': 46,'U05': 47,'S06': 48,'R06': 49,'Q06': 50,'P06': 51,'O06': 52,'N06': 53,'M06': 54,'L06': 55,'K06': 56,'J06': 57,'I06': 58,'F08': 59,'J02': 60,'J07': 61,'I07': 62,'I10': 63,'J10': 64,'D15': 65,'E15': 66,'G15': 67,'J15': 68,'L15': 69,'R15': 70,'T15': 71,'W15': 72,'I08': 73,'I03': 74,'J08': 75,'I01': 76,'I02': 77,'J01': 78,'K01': 79,'K02': 80,'L01': 81,'L02': 82,'M01': 83,'M02': 84,'N01': 85,'N02': 86,'O01': 87,'I09': 88,'D14': 89,'D13': 90,'K07': 91,'K08': 92,'N15': 93,'P15': 94,'I15': 95,'S15': 96,'U15': 97,'V15': 98,'S07': 99,'S08': 100,'L09': 101,'L08': 102,'Q02': 103,'Q01': 104}\n",
    "  df_full['location'] = df_full['location'].map(dict)\n",
    "  df_train=df_full.sample(frac=0.8,random_state=200)\n",
    "  df_valid=df_full.drop(df_train.index)\n",
    "\n",
    "  location_counts = BLE_RSSI.location.value_counts()\n",
    "  train_X = np.asarray(df_train[FEATURES])\n",
    "  train_y = np.asarray(df_train['location'])\n",
    "  feature_columns = [\n",
    "        tf.feature_column.numeric_column(INPUT_FEATURE, shape=[13])\n",
    "  ]\n",
    "  # Train Input Function\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {INPUT_FEATURE: train_X},\n",
    "    y = train_y,\n",
    "    batch_size = 12,\n",
    "    num_epochs = 100,\n",
    "    shuffle = False,\n",
    "\n",
    "  )\n",
    "\n",
    "  # Test Input Function\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {INPUT_FEATURE: train_X},\n",
    "    y = train_y,\n",
    "    batch_size = 12,\n",
    "    num_epochs = 100,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )\n",
    "\n",
    "\n",
    "  config = tf.estimator.RunConfig(model_dir=TF_MODEL_DIR, save_summary_steps=100, save_checkpoints_steps=1000)\n",
    "\n",
    "  # Build 3 layer DNN classifier\n",
    "\n",
    "  model = tf.estimator.DNNClassifier(hidden_units = [13,65,110],\n",
    "                     feature_columns = feature_columns,\n",
    "                     model_dir = TF_MODEL_DIR,\n",
    "                     n_classes=105, config=config\n",
    "                   )\n",
    "\n",
    "  export_final = tf.estimator.FinalExporter(TF_EXPORT_DIR, serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, \n",
    "                                        max_steps=TF_TRAIN_STEPS)\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn,\n",
    "                                      steps=1,\n",
    "                                      exporters=export_final,\n",
    "                                      throttle_secs=1,\n",
    "                                      start_delay_secs=1)\n",
    "\n",
    "  # Train and Evaluate the model\n",
    "\n",
    "  tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Minioclient object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.api.Minio at 0x7fd3d1932c18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minioClient = Minio(s3_endPoint,\n",
    "                    access_key='minio',\n",
    "                    secret_key='minio123',\n",
    "                    secure=False)\n",
    "minioClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model folder and contents into MinIO bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcc43bd53179ca1f819b57b5a9b16dca\n",
      "b8c1f2880ca6e796a1c235033c887f6a\n",
      "7b7837a8f93a9cd849fdc8cec89de0e1\n",
      "ecee47b1281f797c11c83f1686e18d74\n"
     ]
    }
   ],
   "source": [
    "initial_dir='export/' + TF_EXPORT_DIR\n",
    "for dir in os.listdir(os.path.join(TF_MODEL_DIR, initial_dir)):\n",
    "    if re.match( \"^[0-9]+$\", dir):\n",
    "        for subdir in os.listdir(os.path.join(TF_MODEL_DIR, initial_dir, dir)):\n",
    "            if subdir=='variables':\n",
    "                for file in os.listdir(os.path.join(TF_MODEL_DIR, initial_dir, dir, subdir)):\n",
    "                    obj_name = TF_EXPORT_DIR + dir + '/' + subdir + '/' + file\n",
    "                    print(minioClient.fput_object(minio_bucket, obj_name ,os.path.join(TF_MODEL_DIR, initial_dir, dir, subdir, file)))\n",
    "            else:\n",
    "                obj_name = TF_EXPORT_DIR + dir + '/' + subdir\n",
    "                print(minioClient.fput_object(minio_bucket, obj_name, os.path.join(TF_MODEL_DIR, initial_dir, dir, subdir)))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List objects within minio bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1617B375C36D03D6',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-type': 'application/xml',\n",
       "   'server': 'Minio/RELEASE.2018-02-09T22-40-05Z (linux; amd64)',\n",
       "   'vary': 'Origin',\n",
       "   'x-amz-request-id': '1617B375C36D03D6',\n",
       "   'date': 'Fri, 12 Jun 2020 05:05:11 GMT',\n",
       "   'transfer-encoding': 'chunked'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'NextMarker': 'blerssi/1591938294/variables/variables.index',\n",
       " 'Contents': [{'Key': 'blerssi/1591938294/saved_model.pb',\n",
       "   'LastModified': datetime.datetime(2020, 6, 12, 5, 5, 6, 421000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"ecee47b1281f797c11c83f1686e18d74\"',\n",
       "   'Size': 73593,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': '',\n",
       "    'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}},\n",
       "  {'Key': 'blerssi/1591938294/variables/variables.data-00000-of-00002',\n",
       "   'LastModified': datetime.datetime(2020, 6, 12, 5, 5, 6, 409000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"7b7837a8f93a9cd849fdc8cec89de0e1\"',\n",
       "   'Size': 8,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': '',\n",
       "    'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}},\n",
       "  {'Key': 'blerssi/1591938294/variables/variables.data-00001-of-00002',\n",
       "   'LastModified': datetime.datetime(2020, 6, 12, 5, 5, 6, 397000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"dcc43bd53179ca1f819b57b5a9b16dca\"',\n",
       "   'Size': 80028,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': '',\n",
       "    'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}},\n",
       "  {'Key': 'blerssi/1591938294/variables/variables.index',\n",
       "   'LastModified': datetime.datetime(2020, 6, 12, 5, 5, 6, 401000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"b8c1f2880ca6e796a1c235033c887f6a\"',\n",
       "   'Size': 404,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': '',\n",
       "    'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}}],\n",
       " 'Name': 'minioblerssi',\n",
       " 'Prefix': '',\n",
       " 'Delimiter': '',\n",
       " 'MaxKeys': 1000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_response = minio_uploader.client.list_objects(Bucket=minio_bucket)\n",
    "model_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inference service name & model storage URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://minioblerssi/blerssi/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_name = \"blerssiminio\"\n",
    "storageURI = \"s3://\" + minio_bucket + '/' + TF_EXPORT_DIR\n",
    "storageURI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define configuration for inference service creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apiVersion: \"serving.kubeflow.org/v1alpha2\"\\nkind: \"InferenceService\"\\nmetadata:\\n  name: blerssiminio\\n  namespace: anonymous\\nspec:\\n  default:\\n    predictor:\\n      serviceAccountName: minio-sa\\n      tensorflow:\\n        storageUri: s3://minioblerssi/blerssi/\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blerssi_kf = f\"\"\"apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: {svc_name}\n",
    "  namespace: anonymous\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      serviceAccountName: minio-sa\n",
    "      tensorflow:\n",
    "        storageUri: {storageURI}\n",
    "\"\"\"\n",
    "blerssi_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write configuration for creating inference service into .yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blerssi_kfserving = yaml.safe_load(blerssi_kf)\n",
    "with open('blerssi-kfserving.yaml', 'w') as file:\n",
    "    yaml_doc = yaml.dump(blerssi_kfserving,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View contents of .yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: serving.kubeflow.org/v1alpha2\r\n",
      "kind: InferenceService\r\n",
      "metadata:\r\n",
      "  name: blerssiminio\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      serviceAccountName: minio-sa\r\n",
      "      tensorflow:\r\n",
      "        storageUri: s3://minioblerssi/blerssi/\r\n"
     ]
    }
   ],
   "source": [
    "! cat blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the configuration .yaml file\n",
    "\n",
    "By applying the configuration .yaml file, serving of BLERSSI model is done using Kubeflow KFServing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/blerssiminio created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether inferenceservice is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "blerssi-model   http://blerssi-model.anonymous.example.com/v1/models/blerssi-model   True    100                                16h\r\n",
      "blerssiminio    http://blerssiminio.anonymous.example.com/v1/models/blerssiminio     True    100                                68s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservice -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Wait for inference service READY=\"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   b3001  b3002  b3003  b3004  b3005  b3006  b3007  b3008  b3009  b3010  \\\n",
      "0    1.0    1.0    1.0    1.0    1.0  0.390    1.0    1.0    1.0    1.0   \n",
      "1    1.0    1.0    1.0    1.0    1.0  0.390    1.0    1.0    1.0    1.0   \n",
      "2    1.0    1.0    1.0    1.0    1.0  0.385    1.0    1.0    1.0    1.0   \n",
      "3    1.0    1.0    1.0    1.0    1.0  0.385    1.0    1.0    1.0    1.0   \n",
      "4    1.0    1.0    1.0    1.0    1.0  0.385    1.0    1.0    1.0    1.0   \n",
      "\n",
      "   b3011  b3012  b3013  \n",
      "0    1.0    1.0    1.0  \n",
      "1    1.0    1.0    1.0  \n",
      "2    1.0    1.0    1.0  \n",
      "3    1.0    1.0    1.0  \n",
      "4    1.0    1.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv(os.path.join(path, 'iBeacon_RSSI_Labeled.csv')) #Labeled dataset\n",
    "# Input Data Preprocessing \n",
    "df_full = df_full.drop(['date'],axis = 1)\n",
    "df_full = df_full.drop(['location'],axis = 1)\n",
    "df_full[FEATURES] = (df_full[FEATURES])/(-200)\n",
    "print(df_full.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data from serving after setting INGRESS_IP\n",
    "\n",
    "Note - Use one of preprocessed row values from previous cell as values for \"instances\" in the below request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 10.30.118.172...\n",
      "* TCP_NODELAY set\n",
      "* Connected to 10.30.118.172 (10.30.118.172) port 31380 (#0)\n",
      "> POST /v1/models/blerssiminio:predict HTTP/1.1\n",
      "> Host: blerssiminio.anonymous.example.com\n",
      "> User-Agent: curl/7.58.0\n",
      "> Accept: */*\n",
      "> Content-Length: 320\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "* upload completely sent off: 320 out of 320 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 4250\n",
      "< content-type: application/json\n",
      "< date: Fri, 12 Jun 2020 05:07:17 GMT\n",
      "< x-envoy-upstream-service-time: 11795\n",
      "< server: istio-envoy\n",
      "< \n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"class_ids\": [97],\n",
      "            \"classes\": [\"97\"],\n",
      "            \"all_class_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "            \"all_classes\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\"],\n",
      "            \"probabilities\": [1.39185269e-15, 2.16918976e-15, 2.01013917e-09, 7.96217588e-18, 3.83831393e-21, 9.1172e-17, 7.30912423e-18, 1.03872954e-16, 1.34082009e-13, 1.88608181e-18, 4.51229142e-17, 9.21579653e-12, 6.80068072e-24, 3.11731466e-36, 8.17957527e-36, 3.72148753e-27, 1.54146867e-16, 2.913555e-24, 9.02598318e-24, 1.42937847e-22, 2.44774877e-23, 2.62540129e-22, 3.81352248e-26, 6.1307311e-21, 3.20361745e-30, 1.84214102e-37, 3.65491945e-31, 1.15936139e-16, 3.86665288e-26, 1.09839011e-16, 6.94423352e-17, 6.34538561e-18, 1.90421697e-14, 1.32893481e-17, 2.35734e-10, 2.57843033e-18, 3.8270794e-24, 2.1968885e-10, 2.36335895e-10, 9.48063e-12, 2.27666368e-18, 1.23617548e-21, 4.13090333e-22, 5.38458929e-15, 7.60744158e-28, 3.39046057e-25, 6.58754865e-24, 1.53958259e-23, 9.10408578e-27, 4.67768508e-34, 3.93897783e-18, 1.21845779e-24, 8.74975e-17, 7.62790095e-20, 7.49125534e-17, 3.53381801e-16, 5.51653314e-14, 4.74682663e-12, 5.52895462e-17, 8.99633621e-20, 3.15393938e-14, 6.44056422e-19, 1.85460761e-14, 1.43713307e-12, 4.40706805e-20, 4.61164293e-15, 5.50616676e-07, 8.19201628e-18, 5.33497291e-13, 0.0179033857, 2.38172815e-09, 0.00177510292, 0.0948559791, 1.83187403e-08, 1.83645227e-13, 1.73105696e-10, 6.73235063e-18, 2.9969216e-09, 6.88067936e-11, 9.13880086e-22, 4.02146705e-10, 1.85995205e-19, 8.32668726e-11, 9.13163351e-27, 1.74673406e-22, 3.2660396e-17, 1.88637408e-21, 1.97548011e-19, 1.1813122e-24, 1.61129299e-06, 6.90005553e-10, 1.314442e-21, 9.41055424e-18, 1.60816053e-05, 1.10254045e-11, 2.2524888e-14, 2.18041114e-05, 0.505653739, 0.379771769, 2.37188925e-29, 4.48321951e-35, 6.68015121e-29, 2.39112397e-12, 9.83146787e-37, 5.34530219e-20],\n",
      "            \"logits\": [-15.2979908, -14.8542738, -1.11491358, -20.4616814, -28.0991058, -18.0236359, -20.5472603, -17.8932171, -10.7301769, -21.9018841, -18.7269936, -6.49995518, -34.4348717, -62.8459435, -61.8812752, -41.9455261, -17.4984779, -35.2825203, -34.1517868, -31.3894844, -33.1541405, -30.7814884, -39.6185112, -27.630825, -49.0031242, -65.6745758, -51.1739159, -17.7833424, -39.6046753, -17.837368, -18.2958851, -20.6886559, -12.6819725, -19.949419, -3.2581687, -21.5892029, -35.0097923, -3.32866168, -3.25561857, -6.47162151, -21.7136745, -29.2321167, -30.3282261, -13.9450884, -43.5331078, -37.4335136, -34.466713, -33.6177979, -41.0509262, -57.834938, -21.1654606, -36.1543083, -18.0647736, -25.1097412, -18.2200623, -16.6688366, -11.6182928, -7.16339636, -18.5238, -24.9447346, -12.1773911, -22.9763527, -12.7083702, -8.35822296, -25.6583443, -14.1000443, 4.49792099, -20.4332237, -9.3491745, 14.8873825, -0.945291519, 12.576251, 16.5547523, 1.09480691, -10.4156237, -3.56696987, -20.6294594, -0.715531588, -4.48957157, -29.5341949, -2.72405648, -24.2184181, -4.29882288, -41.047905, -31.1889744, -19.0502224, -28.8094845, -24.1581573, -36.1852684, 5.57167387, -2.18417263, -29.1707249, -20.2945518, 7.8723135, -6.32067108, -12.5140066, 8.17673588, 18.2282448, 17.9419632, -47.001133, -60.179985, -45.9656754, -7.84911, -63.9999123, -25.4653378]\n",
      "        }\n",
      "    ]\n",
      "* Connection #0 to host 10.30.118.172 left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -v -H \"Host: blerssiminio.anonymous.example.com\" http://10.30.118.172:31380/v1/models/blerssiminio:predict -d '{\"signature_name\":\"predict\",\"instances\":[{\"b3001\":[-0.458086] , \"b3002\":[-0.6244] , \"b3003\":[2.354243], \"b3004\":[-0.404581] , \"b3005\":[1.421444] , \"b3006\":[1.767642] , \"b3007\":[2.637829] , \"b3008\":[-0.603085] , \"b3009\":[0.382779] , \"b3010\":[-0.378999] , \"b3011\":[-0.341798] , \"b3012\":[-0.303249] , \"b3013\":[-0.327776]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup after prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete minio secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret \"miniosecret\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f minio-secret.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete minio service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount \"minio-sa\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f minio-serviceaccount.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete KFserving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org \"blerssiminio\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete minio bucket & contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1617B395DF0DD38E',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'server': 'Minio/RELEASE.2018-02-09T22-40-05Z (linux; amd64)',\n",
       "   'vary': 'Origin',\n",
       "   'x-amz-request-id': '1617B395DF0DD38E',\n",
       "   'date': 'Fri, 12 Jun 2020 05:07:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_response = minio_uploader.client.list_objects(Bucket=minio_bucket)\n",
    "\n",
    "obj_list = []\n",
    "for obj_name in model_response['Contents']:\n",
    "    obj_list.append({'Key' : obj_name['Key']})\n",
    "\n",
    "minio_uploader.client.delete_objects(Bucket=minio_bucket, Delete={'Objects' : obj_list})\n",
    "minio_uploader.client.delete_bucket(Bucket=minio_bucket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
