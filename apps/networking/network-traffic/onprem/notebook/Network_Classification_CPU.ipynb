{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Dataset for malicious attack\n",
    "\n",
    "This dataset of network traffic flow is generated by CICFlowMeter, indicate whether the traffic is malicious attack (Bot) or not (Benign).                             \n",
    "CICFlowMeter - network traffic flow generator generates 69 statistical features such as Duration, Number of packets, Number of bytes, Length of packets, etc are also calculated separately in the forward and reverse direction.   \n",
    "The output of the application is the CSV file format with two columns labeled for each flow, namely Benign or Bot.\n",
    "The dataset has been organized per day, for each day the raw data including the network traffic (Pcaps) and event logs (windows and Ubuntu event Logs) per machine\n",
    "are recorded.                  Download the dataset from the below wget command line provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cse-cic-ids2018.s3.ca-central-1.amazonaws.com/Processed+Traffic+Data+for+ML+Algorithms/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imblearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in ./.local/lib/python3.6/site-packages (from imblearn) (0.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in ./.local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Notebook Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FEATURE = 'x'\n",
    "\n",
    "lstZerodrp = ['Timestamp', 'BwdPSHFlags', 'FwdURGFlags', 'BwdURGFlags', 'CWEFlagCount', 'FwdBytsbAvg', 'FwdPktsbAvg',\n",
    "              'FwdBlkRateAvg', 'BwdBytsbAvg',\n",
    "              'BwdBlkRateAvg', 'BwdPktsbAvg']\n",
    "\n",
    "lstScaledrp = ['FwdPSHFlags', 'FINFlagCnt', 'SYNFlagCnt', 'RSTFlagCnt', 'PSHFlagCnt', 'ACKFlagCnt', 'URGFlagCnt',\n",
    "               'ECEFlagCnt']\n",
    "\n",
    "DATA_FILE = 'Network_Traffic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataFile():\n",
    "    \"\"\"\n",
    "    Reads data file and returns dataframe result\n",
    "    \"\"\"\n",
    "    chunksize = 10000\n",
    "    chunk_list = []\n",
    "    missing_values = [\"n/a\", \"na\", \"--\", \"Infinity\", \"infinity\", \"Nan\", \"NaN\"]\n",
    "\n",
    "    for chunk in pd.read_csv(DATA_FILE, chunksize=chunksize, na_values=missing_values):\n",
    "        chunk_list.append(chunk)\n",
    "        break\n",
    "    dataFrme = pd.concat(chunk_list)\n",
    "\n",
    "    lstcols = []\n",
    "    for i in dataFrme.columns:\n",
    "        i = str(i).replace(' ', '').replace('/', '')\n",
    "        lstcols.append(i)\n",
    "    dataFrme.columns = lstcols\n",
    "    dfAllCpy = dataFrme.copy()\n",
    "    dataFrme = dataFrme.drop(lstZerodrp, axis=1)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Input Dataset \n",
    "\n",
    "### Attribute Information\n",
    "    Features extracted from the captured traffic using CICFlowMeter-V3 = 69\n",
    "    After removal of noise/unwarranted features, number of feature columns chosen: 10\n",
    "    Features: FlowDuration,BwdPktLenMax,FlowIATStd,FwdPSHFlags,BwdPktLenMean,FlowIATMean,BwdIATMean,\n",
    "              FwdSegSizeMin,InitBwdWinByts,BwdPktLenMin\n",
    "    Flows labelled: Bot or Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DstPort</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>FlowDuration</th>\n",
       "      <th>TotFwdPkts</th>\n",
       "      <th>TotBwdPkts</th>\n",
       "      <th>TotLenFwdPkts</th>\n",
       "      <th>TotLenBwdPkts</th>\n",
       "      <th>FwdPktLenMax</th>\n",
       "      <th>FwdPktLenMin</th>\n",
       "      <th>FwdPktLenMean</th>\n",
       "      <th>...</th>\n",
       "      <th>FwdSegSizeMin</th>\n",
       "      <th>ActiveMean</th>\n",
       "      <th>ActiveStd</th>\n",
       "      <th>ActiveMax</th>\n",
       "      <th>ActiveMin</th>\n",
       "      <th>IdleMean</th>\n",
       "      <th>IdleStd</th>\n",
       "      <th>IdleMax</th>\n",
       "      <th>IdleMin</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>61.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>98.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>142.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DstPort  Protocol  FlowDuration  TotFwdPkts  TotBwdPkts  TotLenFwdPkts  \\\n",
       "0      443         6        141385           9           7            553   \n",
       "1    49684         6           281           2           1             38   \n",
       "2      443         6        279824          11          15           1086   \n",
       "3      443         6           132           2           0              0   \n",
       "4      443         6        274016           9          13           1285   \n",
       "\n",
       "   TotLenBwdPkts  FwdPktLenMax  FwdPktLenMin  FwdPktLenMean  ...  \\\n",
       "0           3773           202             0      61.444444  ...   \n",
       "1              0            38             0      19.000000  ...   \n",
       "2          10527           385             0      98.727273  ...   \n",
       "3              0             0             0       0.000000  ...   \n",
       "4           6141           517             0     142.777778  ...   \n",
       "\n",
       "   FwdSegSizeMin  ActiveMean  ActiveStd  ActiveMax  ActiveMin  IdleMean  \\\n",
       "0             20         0.0        0.0        0.0        0.0       0.0   \n",
       "1             20         0.0        0.0        0.0        0.0       0.0   \n",
       "2             20         0.0        0.0        0.0        0.0       0.0   \n",
       "3             20         0.0        0.0        0.0        0.0       0.0   \n",
       "4             20         0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "   IdleStd  IdleMax  IdleMin   Label  \n",
       "0      0.0      0.0      0.0  Benign  \n",
       "1      0.0      0.0      0.0  Benign  \n",
       "2      0.0      0.0      0.0  Benign  \n",
       "3      0.0      0.0      0.0  Benign  \n",
       "4      0.0      0.0      0.0  Benign  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataFile().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_na(dataFrme):\n",
    "    \"\"\"\n",
    "    Removing NA values\n",
    "    \"\"\"\n",
    "    na_lst = dataFrme.columns[dataFrme.isna().any()].tolist()\n",
    "    for j in na_lst:\n",
    "        dataFrme[j].fillna(0, inplace=True)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_label(dataFrme):\n",
    "    \"\"\"\n",
    "    Create independent and Dependent Features\n",
    "    \"\"\"\n",
    "    columns = dataFrme.columns.tolist()\n",
    "    # Filter the columns to remove data we do not want \n",
    "    columns = [c for c in columns if c not in [\"Label\"]]\n",
    "    # Store the variable we are predicting \n",
    "    target = \"Label\"\n",
    "    # Define a random state \n",
    "    state = np.random.RandomState(42)\n",
    "    X = dataFrme[columns]\n",
    "    Y = dataFrme[target]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_substitution(dataFrme):\n",
    "    \"\"\"\n",
    "    Label substitution : 'Benign'as 0, 'Bot'as 1\n",
    "    \"\"\"\n",
    "    dictLabel = {'Benign': 0, 'Bot': 1}\n",
    "    dataFrme['Label'] = dataFrme['Label'].map(dictLabel)\n",
    "\n",
    "    LABELS = ['Benign', 'Bot']\n",
    "    count_classes = pd.value_counts(dataFrme['Label'], sort=True)\n",
    "    \n",
    "    # Get the Benign and the Bot values \n",
    "    Benign = dataFrme[dataFrme['Label'] == 0]\n",
    "    Bot = dataFrme[dataFrme['Label'] == 1]\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X,Y):\n",
    "    \"\"\"\n",
    "    Handle Class imbalancement \n",
    "    \"\"\"\n",
    "#    os_us = SMOTETomek(ratio=0.5)\n",
    "#    X_res, y_res = os_us.fit_sample(X, Y)\n",
    "    ros = RandomOverSampler(random_state=50)\n",
    "    X_res, y_res = ros.fit_sample(X, Y)\n",
    "    ibtrain_X = pd.DataFrame(X_res,columns=X.columns)\n",
    "    ibtrain_y = pd.DataFrame(y_res,columns=['Label']) \n",
    "    return ibtrain_X,ibtrain_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_features(ibtrain_X):\n",
    "    \"\"\"\n",
    "    Feature Selection - Correlation Ananlysis \n",
    "    \"\"\"\n",
    "    corr = ibtrain_X.corr()\n",
    "    cor_columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= 0.9:\n",
    "                if cor_columns[j]:\n",
    "                    cor_columns[j] = False\n",
    "\n",
    "    dfcorr_features = ibtrain_X[corr.columns[cor_columns]]\n",
    "    return dfcorr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_features(dfcorr_features, ibtrain_X, ibtrain_y):\n",
    "    \"\"\"\n",
    "    Feature Selection - SelectKBest : Return best 10 features. \n",
    "    \"\"\"\n",
    "    feat_X = dfcorr_features\n",
    "    feat_y = ibtrain_y['Label']\n",
    "    # apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "    fit = bestfeatures.fit(feat_X, feat_y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(feat_X.columns)\n",
    "    # concat two dataframes for better visualization\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    final_feature = featureScores.nlargest(10, 'Score')['Features'].tolist()\n",
    "    dictLabel1 = {'Benign': 0, 'Bot': 1}\n",
    "    ibtrain_y['Label'] = ibtrain_y['Label'].map(dictLabel1)\n",
    "    selected_X = ibtrain_X[final_feature]\n",
    "    selected_Y = ibtrain_y['Label']\n",
    "    return selected_X, selected_Y, final_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(selected_X, selected_Y):\n",
    "    \"\"\"\n",
    "    Normalize data \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    selected_X = pd.DataFrame(scaler.fit_transform(selected_X), columns=selected_X.columns, index=selected_X.index)\n",
    "    trainX, testX, trainY, testY = train_test_split(selected_X, selected_Y, test_size=0.25)\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"## Final features and Data pre-process for prediction\")\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(testX)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Serving Input Receiver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"\n",
    "    This is used to define inputs to serve the model.\n",
    "    :return: ServingInputReciever\n",
    "    \"\"\"\n",
    "    receiver_tensors = {\n",
    "        'FlowDuration': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'BwdPktLenMax': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'FlowIATStd': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'BwdPktLenMean': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'FwdPSHFlags': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'FlowIATMean': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'BwdIATMean': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'FwdSegSizeMin': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'InitBwdWinByts': tf.placeholder(tf.float32, [None, 1]),\n",
    "        'BwdPktLenMin': tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    }\n",
    "\n",
    "    # Convert give inputs to adjust to the model.\n",
    "    features = {\n",
    "        INPUT_FEATURE: tf.concat([\n",
    "            receiver_tensors['FlowDuration'],\n",
    "            receiver_tensors['BwdPktLenMax'],\n",
    "            receiver_tensors['FlowIATStd'],\n",
    "            receiver_tensors['BwdPktLenMean'],\n",
    "            receiver_tensors['FwdPSHFlags'],\n",
    "            receiver_tensors['FlowIATMean'],\n",
    "            receiver_tensors['BwdIATMean'],\n",
    "            receiver_tensors['FwdSegSizeMin'],\n",
    "            receiver_tensors['InitBwdWinByts'],\n",
    "            receiver_tensors['BwdPktLenMin'],\n",
    "        ], axis=1)\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(receiver_tensors=receiver_tensors,\n",
    "                                                    features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(trainX, trainY, testX, testY, final_feature):\n",
    "    \n",
    "    \"\"\"\n",
    "    Training and Evalution\n",
    "    \"\"\"\n",
    "    \n",
    "    TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/tmp/data/\")\n",
    "    TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"network/\")\n",
    "    TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"network/\")\n",
    "\n",
    "    train_X = np.asarray(trainX)\n",
    "    train_y = np.asarray(trainY)\n",
    "    feature_columns = [tf.feature_column.numeric_column(INPUT_FEATURE, shape=[10])]\n",
    "\n",
    "    config = tf.estimator.RunConfig(model_dir=TF_MODEL_DIR, save_summary_steps=10, save_checkpoints_steps=10)\n",
    "\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_FEATURE: train_X},\n",
    "        y=train_y,\n",
    "        batch_size=32,\n",
    "        num_epochs=10,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_FEATURE: train_X},\n",
    "        y=train_y,\n",
    "        batch_size=32,\n",
    "        num_epochs=10,\n",
    "        shuffle=True,\n",
    "        queue_capacity=10,\n",
    "        num_threads=1\n",
    "    )\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(hidden_units=[13, 65, 110],\n",
    "                                       feature_columns=feature_columns,\n",
    "                                       model_dir=TF_MODEL_DIR,\n",
    "                                       n_classes=2, config=config\n",
    "                                       )\n",
    "\n",
    "    export_final = tf.estimator.FinalExporter(TF_EXPORT_DIR, serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\n",
    "                                        max_steps=1)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn,\n",
    "                                      steps=1,\n",
    "                                      exporters=export_final,\n",
    "                                      throttle_secs=1,\n",
    "                                      start_delay_secs=1)\n",
    "\n",
    "    result = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Network Traffic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "## Final features and Data pre-process for prediction\n",
      "-----------------------------------------------------------------\n",
      "       FlowDuration  BwdIATTot  BwdPktLenMax  FlowIATStd  BwdPktLenMean  \\\n",
      "7678   4.808377e-06   0.000000      0.000000    0.000000       0.000000   \n",
      "7355   4.150038e-06   0.000000      0.000000    0.000000       0.000000   \n",
      "1638   4.050037e-06   0.000000      0.000000    0.000000       0.000000   \n",
      "5709   4.183371e-06   0.000000      0.000000    0.000000       0.000000   \n",
      "276    2.347830e-03   0.000000      0.000000    0.004407       0.000000   \n",
      "...             ...        ...           ...         ...            ...   \n",
      "3842   7.796737e-05   0.000075      0.076712    0.000093       0.023585   \n",
      "11563  8.333409e-09   0.000000      0.000000    0.000000       0.000000   \n",
      "9802   9.260917e-05   0.000089      0.076712    0.000111       0.023585   \n",
      "882    9.928674e-01   0.983333      0.034932    0.013026       0.034306   \n",
      "10505  2.601190e-04   0.000000      0.000000    0.000000       0.000000   \n",
      "\n",
      "       FwdPSHFlags  BwdIATMean  FwdSegSizeMin   FlowIATMean  InitBwdWinByts  \n",
      "7678           0.0    0.000000            1.0  4.848739e-06        0.000000  \n",
      "7355           0.0    0.000000            1.0  4.184874e-06        0.000000  \n",
      "1638           0.0    0.000000            1.0  4.084034e-06        0.000000  \n",
      "5709           0.0    0.000000            1.0  4.218487e-06        0.000000  \n",
      "276            0.0    0.000000            1.0  7.891793e-04        0.125015  \n",
      "...            ...         ...            ...           ...             ...  \n",
      "3842           0.0    0.000047            1.0  1.310364e-05        0.003357  \n",
      "11563          1.0    0.000000            1.0  8.403361e-09        0.000000  \n",
      "9802           0.0    0.000056            1.0  1.556443e-05        0.003357  \n",
      "882            1.0    0.012055            1.0  3.282629e-03        0.957535  \n",
      "10505          0.0    0.000000            1.0  2.623025e-04        0.000000  \n",
      "\n",
      "[4260 rows x 10 columns]\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'network/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd5425c41d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [23] are constant.\n",
      "  UserWarning)\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "I0421 09:58:49.229977 140556435072832 estimator.py:209] Using config: {'_model_dir': 'network/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd5425c41d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:49.232479 140556435072832 estimator_training.py:186] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:49.233749 140556435072832 training.py:612] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:49.234976 140556435072832 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.256448 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.268494 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.271283 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:49.278822 140556435072832 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.284144 140556435072832 deprecation.py:506] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.881215 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:49.947916 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:50.136243 140556435072832 deprecation.py:506] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.174300 140556435072832 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.175942 140556435072832 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.320286 140556435072832 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.385766 140556435072832 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.391565 140556435072832 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:50.406064 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into network/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.619344 140556435072832 basic_session_run_hooks.py:606] Saving checkpoints for 0 into network/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 21.61299, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.821840 140556435072832 basic_session_run_hooks.py:262] loss = 21.61299, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into network/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.823867 140556435072832 basic_session_run_hooks.py:606] Saving checkpoints for 1 into network/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:50.889825 140556435072832 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:2027: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:51.151136 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:2027: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:51.540073 140556435072832 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:51.557292 140556435072832 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.573993 140556435072832 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-21T09:58:51Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.589221 140556435072832 evaluation.py:255] Starting evaluation at 2020-04-21T09:58:51Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.678585 140556435072832 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:51.681171 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.683492 140556435072832 saver.py:1280] Restoring parameters from network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.734582 140556435072832 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.759773 140556435072832 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:51.967252 140556435072832 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-21-09:58:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.136378 140556435072832 evaluation.py:275] Finished evaluation at 2020-04-21-09:58:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.53125, accuracy_baseline = 0.53125, auc = 0.7431372, auc_precision_recall = 0.7068181, average_loss = 0.6070869, global_step = 1, label/mean = 0.46875, loss = 19.42678, precision = 0.0, prediction/mean = 0.4088927, recall = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.138460 140556435072832 estimator.py:2039] Saving dict for global step 1: accuracy = 0.53125, accuracy_baseline = 0.53125, auc = 0.7431372, auc_precision_recall = 0.7068181, average_loss = 0.6070869, global_step = 1, label/mean = 0.46875, loss = 19.42678, precision = 0.0, prediction/mean = 0.4088927, recall = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.242865 140556435072832 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1: network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Performing the final export in the end of training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.244974 140556435072832 exporter.py:410] Performing the final export in the end of training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.255735 140556435072832 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.581747 140556435072832 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:52.584490 140556435072832 deprecation.py:323] From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.586727 140556435072832 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.587942 140556435072832 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.589061 140556435072832 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.590137 140556435072832 export_utils.py:170] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.591190 140556435072832 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.592355 140556435072832 export_utils.py:173] Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.593506 140556435072832 export_utils.py:176] 'serving_default' : Classification input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.594688 140556435072832 export_utils.py:176] 'classification' : Classification input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.595860 140556435072832 export_utils.py:176] 'regression' : Regression input must be a single string Tensor; got {'FlowDuration': <tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMax': <tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>, 'FlowIATStd': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_3:0' shape=(?, 1) dtype=float32>, 'FwdPSHFlags': <tf.Tensor 'Placeholder_4:0' shape=(?, 1) dtype=float32>, 'FlowIATMean': <tf.Tensor 'Placeholder_5:0' shape=(?, 1) dtype=float32>, 'BwdIATMean': <tf.Tensor 'Placeholder_6:0' shape=(?, 1) dtype=float32>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_7:0' shape=(?, 1) dtype=float32>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_8:0' shape=(?, 1) dtype=float32>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_9:0' shape=(?, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 09:58:52.597010 140556435072832 export_utils.py:182] Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.645568 140556435072832 saver.py:1280] Restoring parameters from network/model.ckpt-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.666398 140556435072832 builder_impl.py:661] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.668029 140556435072832 builder_impl.py:456] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: network/export/network/temp-b'1587463132'/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.712650 140556435072832 builder_impl.py:421] SavedModel written to: network/export/network/temp-b'1587463132'/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 21.61299.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 09:58:52.789323 140556435072832 estimator.py:368] Loss for final step: 21.61299.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'accuracy': 0.53125, 'accuracy_baseline': 0.53125, 'auc': 0.7431372, 'auc_precision_recall': 0.7068181, 'average_loss': 0.6070869, 'label/mean': 0.46875, 'loss': 19.42678, 'precision': 0.0, 'prediction/mean': 0.4088927, 'recall': 0.0, 'global_step': 1}, [b'network/export/network/1587463132'])\n",
      "Training finished successfully\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_args):\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    '''Reads data file and returns dataframe result'''\n",
    "    dataFrme = read_dataFile()\n",
    "  \n",
    "    ''' Removing NA values'''\n",
    "    dataFrme = preprocess_na(dataFrme)\n",
    "\n",
    "    '''Create independent and Dependent Features'''\n",
    "    X, Y = create_features_label(dataFrme)\n",
    "\n",
    "    '''Label substitution : 'Benign'as 0, 'Bot'as 1'''\n",
    "    dataFrme = label_substitution(dataFrme)\n",
    "\n",
    "    '''Handle Class imbalancement'''\n",
    "    ibtrain_X, ibtrain_y = handle_class_imbalance(X, Y)\n",
    "\n",
    "    '''Feature Selection - Correlation Ananlysis'''\n",
    "    dfcorr_features = correlation_features(ibtrain_X)\n",
    "\n",
    "    '''Feature Selection - SelectKBest : Return best 10 features'''\n",
    "    selected_X, selected_Y, final_feature = top_ten_features(dfcorr_features, ibtrain_X, ibtrain_y)\n",
    "\n",
    "    '''Normalize data '''\n",
    "    trainX, testX, trainY, testY = normalize_data(selected_X, selected_Y)\n",
    "    \n",
    "    '''Train and Evaluate'''\n",
    "    get_model(trainX, trainY, testX, testY, final_feature)\n",
    "\n",
    "    print('Training finished successfully')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update  storageUri in network_kfserving.yaml with pvc-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\r\n",
      "kind: \"InferenceService\"\r\n",
      "metadata:\r\n",
      "  name: \"network-model\"\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      tensorflow:\r\n",
      "        storageUri: \"pvc://workspace-network/network/export/network\"\r\n"
     ]
    }
   ],
   "source": [
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/nfs/$pvc/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Network Traffic Model using kubeflow kfserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/network-model created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f network_kfserving.yaml -n anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "network-model   http://network-model.anonymous.example.com/v1/models/network-model   True    100                                28s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Wait for inference service READY=\\\"True\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data from serving after setting INGRESS_IP\n",
    "### Note - Use one of preprocessed row values from Data pre-process for prediction output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 10.30.118.172...\n",
      "* TCP_NODELAY set\n",
      "* Connected to 10.30.118.172 (10.30.118.172) port 31380 (#0)\n",
      "> POST /v1/models/network-model:predict HTTP/1.1\n",
      "> Host: network-model.anonymous.example.com\n",
      "> User-Agent: curl/7.58.0\n",
      "> Accept: */*\n",
      "> Content-Length: 339\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "* upload completely sent off: 339 out of 339 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 318\n",
      "< content-type: application/json\n",
      "< date: Tue, 21 Apr 2020 10:05:58 GMT\n",
      "< x-envoy-upstream-service-time: 9568\n",
      "< server: istio-envoy\n",
      "< \n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"logits\": [-1.10299587],\n",
      "            \"class_ids\": [0],\n",
      "            \"classes\": [\"0\"],\n",
      "            \"all_class_ids\": [0, 1],\n",
      "            \"logistic\": [0.249178976],\n",
      "            \"all_classes\": [\"0\", \"1\"],\n",
      "            \"probabilities\": [0.750821054, 0.249178976]\n",
      "        }\n",
      "    ]\n",
      "* Connection #0 to host 10.30.118.172 left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "! curl -v -H \"Host: network-model.anonymous.example.com\" http://<<INGRESS_IP>>:<<PORT>>/v1/models/network-model:predict -d '{\"signature_name\":\"predict\",\"instances\":[{\"FlowDuration\":[0.45808569] , \"BwdPktLenMax\":[0.62440011] , \"FlowIATStd\":[2.35424276], \"FwdPSHFlags\":[0.45808569] , \"BwdPktLenMean\":[0.62440011] , \"FlowIATMean\":[2.35424276] , \"BwdIATMean\":[0.45808569] , \"FwdSegSizeMin\":[0.62440011] , \"InitBwdWinByts\":[2.35424276] , \"BwdPktLenMin\":[0.62440011]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete kfserving model & Clean up of stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org \"network-model\" deleted\n",
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
      "kind: \"InferenceService\"\n",
      "metadata:\n",
      "  name: \"network-model\"\n",
      "  namespace: anonymous\n",
      "spec:\n",
      "  default:\n",
      "    predictor:\n",
      "      tensorflow:\n",
      "        storageUri: \"pvc://nfs/network/export/network\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f network_kfserving.yaml\n",
    "!rm -rf /mnt/network\n",
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/$pvc/nfs/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
