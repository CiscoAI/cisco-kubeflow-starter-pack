{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chest-Xray Dataset Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - To Generate the Xray datasets, download the links listed above :\n",
    "\n",
    "    git clone https://github.com/ieee8023/covid-chestxray-dataset.git  \n",
    "    git clone https://github.com/agchung/Figure1-COVID-chestxray-dataset.git  \n",
    "    git clone https://github.com/agchung/Actualmed-COVID-chestxray-dataset.git  \n",
    "    \n",
    "\n",
    " - Go to this <a href=\"https://www.kaggle.com/tawsifurrahman/covid19-radiography-database\"> link </a> to download the COVID-19  - Radiography database. Only the COVID-19 image folder and metadata file is required. The overlaps between covid-chestxray-dataset are handled.  \n",
    " - Go to this <a href=\"https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\"> link </a> to download the RSNA pneumonia dataset.\n",
    " - Create a datasets directory and within the datasets directory, create covid and normal directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/agchung/Figure1-COVID-chestxray-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/agchung/Actualmed-COVID-chestxray-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :\n",
    "1. Download dataset from https://www.kaggle.com/tawsifurrahman/covid19-radiography-database URL and save it in this location\n",
    "2. Download dataset from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data URL and save it in this location "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kubeflow-fairing==0.7.2 kfserving xlrd pandas opencv-python pydicom pillow scikit-learn imutils minio kubernetes --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Notebook Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "import shutil\n",
    "import logging\n",
    "import yaml\n",
    "from minio import Minio\n",
    "from zipfile import ZipFile\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes.client import rest as k8s_rest\n",
    "from kubernetes import config as k8s_config\n",
    "from kubernetes.client.rest import ApiException\n",
    "from kubeflow.fairing.cloud.k8s import MinioUploader\n",
    "from kubeflow.fairing.builders.cluster.minio_context import MinioContextSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip \"576013_1042828_compressed_COVID-19 Radiography Database.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf \"576013_1042828_compressed_COVID-19 Radiography Database.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip \"rsna-pneumonia-detection-challenge.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf \"rsna-pneumonia-detection-challenge.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed) # Reset the seed so all runs are the same.\n",
    "random.seed(seed)\n",
    "MAXVAL = 255  # Range [0 255]\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/ieee8023/covid-chestxray-dataset\n",
    "cohen_imgpath = 'covid-chestxray-dataset/images' \n",
    "cohen_csvpath = 'covid-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/agchung/Figure1-COVID-chestxray-dataset\n",
    "fig1_imgpath = 'Figure1-COVID-chestxray-dataset/images'\n",
    "fig1_csvpath = 'Figure1-COVID-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/agchung/Actualmed-COVID-chestxray-dataset\n",
    "actmed_imgpath = 'Actualmed-COVID-chestxray-dataset/images'\n",
    "actmed_csvpath = 'Actualmed-COVID-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# # path to covid-19 dataset from https://www.kaggle.com/tawsifurrahman/covid19-radiography-database\n",
    "sirm_imgpath = 'COVID-19'\n",
    "sirm_csvpath = 'COVID-19.metadata.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir rsna-pneumonia-detection-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv stage_2_detailed_class_info.csv rsna-pneumonia-detection-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv stage_2_train_labels.csv rsna-pneumonia-detection-challenge\n",
    "! mv stage_2_train_images rsna-pneumonia-detection-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir datasets/covid\n",
    "! mkdir datasets/normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n",
    "rsna_datapath = 'rsna-pneumonia-detection-challenge'\n",
    "# get all the normal from here\n",
    "rsna_csvname = 'stage_2_detailed_class_info.csv' \n",
    "# get all the 1s from here since 1 indicate pneumonia\n",
    "# found that images that aren't pneunmonia and also not normal are classified as 0s\n",
    "rsna_csvname2 = 'stage_2_train_labels.csv' \n",
    "rsna_imgpath = 'stage_2_train_images'\n",
    "\n",
    "# parameters for COVIDx dataset\n",
    "train = []\n",
    "test = []\n",
    "test_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "train_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "\n",
    "mapping = dict()\n",
    "mapping['COVID-19'] = 'COVID-19'\n",
    "mapping['SARS'] = 'pneumonia'\n",
    "mapping['MERS'] = 'pneumonia'\n",
    "mapping['Streptococcus'] = 'pneumonia'\n",
    "mapping['Klebsiella'] = 'pneumonia'\n",
    "mapping['Chlamydophila'] = 'pneumonia'\n",
    "mapping['Legionella'] = 'pneumonia'\n",
    "mapping['Normal'] = 'normal'\n",
    "mapping['Lung Opacity'] = 'pneumonia'\n",
    "mapping['1'] = 'pneumonia'\n",
    "\n",
    "# train/test split\n",
    "split = 0.1\n",
    "\n",
    "# to avoid duplicates\n",
    "patient_imgpath = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_csv = pd.read_csv(cohen_csvpath, nrows=None)\n",
    "#idx_pa = csv[\"view\"] == \"PA\"  # Keep only the PA view\n",
    "views = [\"PA\", \"AP\", \"AP Supine\", \"AP semi erect\", \"AP erect\"]\n",
    "cohen_idx_keep = cohen_csv.view.isin(views)\n",
    "cohen_csv = cohen_csv[cohen_idx_keep]\n",
    "\n",
    "fig1_csv = pd.read_csv(fig1_csvpath, encoding='ISO-8859-1', nrows=None)\n",
    "actmed_csv = pd.read_csv(actmed_csvpath, nrows=None)\n",
    "\n",
    "sirm_csv = pd.read_excel(sirm_csvpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmed\n",
    "# stored as patient id, image filename and label\n",
    "filename_label = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
    "count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "covid_ds = {'cohen': [], 'fig1': [], 'actmed': [], 'sirm': []}\n",
    "\n",
    "for index, row in cohen_csv.iterrows():\n",
    "    f = row['finding'].split(',')[0] # take the first finding, for the case of COVID-19, ARDS\n",
    "    if f in mapping: # \n",
    "        count[mapping[f]] += 1\n",
    "        entry = [str(row['patientid']), row['filename'], mapping[f], 'cohen']\n",
    "        filename_label[mapping[f]].append(entry)\n",
    "        if mapping[f] == 'COVID-19':\n",
    "            covid_ds['cohen'].append(str(row['patientid']))\n",
    "        \n",
    "for index, row in fig1_csv.iterrows():\n",
    "    if not str(row['finding']) == 'nan':\n",
    "        f = row['finding'].split(',')[0] # take the first finding\n",
    "        if f in mapping: # \n",
    "            count[mapping[f]] += 1\n",
    "            if os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.jpg')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.jpg', mapping[f], 'fig1']\n",
    "            elif os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.png')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.png', mapping[f], 'fig1']\n",
    "            filename_label[mapping[f]].append(entry)\n",
    "            if mapping[f] == 'COVID-19':\n",
    "                covid_ds['fig1'].append(row['patientid'])\n",
    "\n",
    "for index, row in actmed_csv.iterrows():\n",
    "    if not str(row['finding']) == 'nan':\n",
    "        f = row['finding'].split(',')[0]\n",
    "        if f in mapping:\n",
    "            count[mapping[f]] += 1\n",
    "            entry = [row['patientid'], row['imagename'], mapping[f], 'actmed']\n",
    "            filename_label[mapping[f]].append(entry)\n",
    "            if mapping[f] == 'COVID-19':\n",
    "                covid_ds['actmed'].append(row['patientid'])\n",
    "                \n",
    "sirm = set(sirm_csv['URL'])\n",
    "cohen = set(cohen_csv['url'])\n",
    "discard = ['100', '101', '102', '103', '104', '105', \n",
    "           '110', '111', '112', '113', '122', '123', \n",
    "           '124', '125', '126', '217']\n",
    "\n",
    "for idx, row in sirm_csv.iterrows():\n",
    "    patientid = row['FILE NAME']\n",
    "    if row['URL'] not in cohen and patientid[patientid.find('(')+1:patientid.find(')')] not in discard:\n",
    "        count[mapping['COVID-19']] += 1\n",
    "        imagename = patientid + '.' + row['FORMAT'].lower()\n",
    "        if not os.path.exists(os.path.join(sirm_imgpath, imagename)):\n",
    "            imagename = patientid.split('(')[0] + ' ('+ patientid.split('(')[1] + '.' + row['FORMAT'].lower()\n",
    "        entry = [patientid, imagename, mapping['COVID-19'], 'sirm']\n",
    "        filename_label[mapping['COVID-19']].append(entry)\n",
    "        covid_ds['sirm'].append(patientid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data distribution from covid datasets:')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Covid Xrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_imgpath = {'cohen': cohen_imgpath, 'fig1': fig1_imgpath, 'actmed': actmed_imgpath, 'sirm': sirm_imgpath}\n",
    "\n",
    "for key in filename_label.keys():\n",
    "    arr = np.array(filename_label[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    # split by patients\n",
    "    # num_diff_patients = len(np.unique(arr[:,0]))\n",
    "    # num_test = max(1, round(split*num_diff_patients))\n",
    "    # select num_test number of random patients\n",
    "    # random.sample(list(arr[:,0]), num_test)\n",
    "    if key == 'pneumonia':\n",
    "        test_patients = ['8', '31']\n",
    "    elif key == 'COVID-19':\n",
    "        test_patients = ['19', '20', '36', '42', '86', \n",
    "                         '94', '97', '117', '132', \n",
    "                         '138', '144', '150', '163', '169', '174', '175', '179', '190', '191'\n",
    "                         'COVID-00024', 'COVID-00025', 'COVID-00026', 'COVID-00027', 'COVID-00029',\n",
    "                         'COVID-00030', 'COVID-00032', 'COVID-00033', 'COVID-00035', 'COVID-00036',\n",
    "                         'COVID-00037', 'COVID-00038',\n",
    "                         'ANON24', 'ANON45', 'ANON126', 'ANON106', 'ANON67',\n",
    "                         'ANON153', 'ANON135', 'ANON44', 'ANON29', 'ANON201', \n",
    "                         'ANON191', 'ANON234', 'ANON110', 'ANON112', 'ANON73', \n",
    "                         'ANON220', 'ANON189', 'ANON30', 'ANON53', 'ANON46',\n",
    "                         'ANON218', 'ANON240', 'ANON100', 'ANON237', 'ANON158',\n",
    "                         'ANON174', 'ANON19', 'ANON195',\n",
    "                         'COVID-19(119)', 'COVID-19(87)', 'COVID-19(70)', 'COVID-19(94)', \n",
    "                         'COVID-19(215)', 'COVID-19(77)', 'COVID-19(213)', 'COVID-19(81)', \n",
    "                         'COVID-19(216)', 'COVID-19(72)', 'COVID-19(106)', 'COVID-19(131)', \n",
    "                         'COVID-19(107)', 'COVID-19(116)', 'COVID-19(95)', 'COVID-19(214)', \n",
    "                         'COVID-19(129)']\n",
    "    else: \n",
    "        test_patients = []\n",
    "    print('Key: ', key)\n",
    "    print('Test patients: ', test_patients)\n",
    "    # go through all the patients\n",
    "    for patient in arr:\n",
    "        if patient[0] not in patient_imgpath:\n",
    "            patient_imgpath[patient[0]] = [patient[1]]\n",
    "        else:\n",
    "            if patient[1] not in patient_imgpath[patient[0]]:\n",
    "                patient_imgpath[patient[0]].append(patient[1])\n",
    "            else:\n",
    "                continue  # skip since image has already been written\n",
    "        if patient[0] in test_patients:\n",
    "            if patient[3] == 'sirm':\n",
    "                image = cv2.imread(os.path.join(ds_imgpath[patient[3]], patient[1]))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                patient[1] = patient[1].replace(' ', '')\n",
    "#                 covid area - test\n",
    "                cv2.imwrite(os.path.join('datasets', 'covid', patient[1]), gray)\n",
    "            else:\n",
    "                if patient[-2] == 'COVID-19':\n",
    "                    copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join('datasets', 'covid', patient[1]))\n",
    "#                 elif patient[-2] == 'pneumonia':\n",
    "#                     copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join('datasets', 'pneumonia', patient[1]))\n",
    "\n",
    "            test.append(patient)\n",
    "            test_count[patient[2]] += 1\n",
    "        else:\n",
    "            if patient[3] == 'sirm':\n",
    "                image = cv2.imread(os.path.join(ds_imgpath[patient[3]], patient[1]))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                patient[1] = patient[1].replace(' ', '')\n",
    "#                 covid area - train\n",
    "                cv2.imwrite(os.path.join('datasets', 'covid', patient[1]), gray)\n",
    "            else:\n",
    "                if patient[-2] == 'COVID-19':\n",
    "                    copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join('datasets', 'covid', patient[1]))\n",
    "#                 elif patient[-2] == 'pneumonia':\n",
    "#                     copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join('datasets', 'pneumonia', patient[1]))\n",
    "            train.append(patient)\n",
    "            train_count[patient[2]] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Normal Xrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_normal = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname), nrows=None)\n",
    "csv_pneu = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname2), nrows=None)\n",
    "patients = {'normal': [], 'pneumonia': []}\n",
    "\n",
    "for index, row in csv_normal.iterrows():\n",
    "    if row['class'] == 'Normal':\n",
    "        patients['normal'].append(row['patientId'])\n",
    "\n",
    "for index, row in csv_pneu.iterrows():\n",
    "    if int(row['Target']) == 1:\n",
    "        patients['pneumonia'].append(row['patientId'])\n",
    "\n",
    "for key in patients.keys():\n",
    "    arr = np.array(patients[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    test_patients = np.load('rsna_test_patients_{}.npy'.format(key)) # random.sample(list(arr), num_test), download the .npy files from the repo.\n",
    "    # np.save('rsna_test_patients_{}.npy'.format(key), np.array(test_patients))\n",
    "    for patient in arr:\n",
    "        if patient not in patient_imgpath:\n",
    "            patient_imgpath[patient] = [patient]\n",
    "        else:\n",
    "            continue  # skip since image has already been written\n",
    "                \n",
    "        ds = dicom.dcmread(os.path.join(rsna_datapath, rsna_imgpath, patient + '.dcm'))\n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        imgname = patient + '.png'\n",
    "        if patient in test_patients:\n",
    "            if key =='normal':\n",
    "                cv2.imwrite(os.path.join('datasets', 'normal', imgname), pixel_array_numpy)\n",
    "#             elif key =='pneumonia':\n",
    "#                 cv2.imwrite(os.path.join('datasets', 'pneumonia', imgname), pixel_array_numpy)\n",
    "            test.append([patient, imgname, key, 'rsna'])\n",
    "            test_count[key] += 1\n",
    "        else:\n",
    "            if key =='normal':\n",
    "                cv2.imwrite(os.path.join('datasets', 'normal', imgname), pixel_array_numpy)\n",
    "#             elif key =='pneumonia':\n",
    "#                 cv2.imwrite(os.path.join('datasets', 'pneumonia', imgname), pixel_array_numpy)\n",
    "            train.append([patient, imgname, key, 'rsna'])\n",
    "            train_count[key] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"dataset\", 'zip', \"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to minio service using credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_config.load_incluster_config()\n",
    "api_client = k8s_client.CoreV1Api()\n",
    "minio_service_endpoint = None\n",
    "\n",
    "try:\n",
    "    minio_service_endpoint = api_client.read_namespaced_service(name='minio-service', namespace='kubeflow').spec.cluster_ip\n",
    "except ApiException as e:\n",
    "    if e.status == 403:\n",
    "        logging.warning(f\"The service account doesn't have sufficient privileges \"\n",
    "                      f\"to get the kubeflow minio-service. \"\n",
    "                      f\"You will have to manually enter the minio cluster-ip. \"\n",
    "                      f\"To make this function work ask someone with cluster \"\n",
    "                      f\"priveleges to create an appropriate \"\n",
    "                      f\"clusterrolebinding by running a command.\\n\"\n",
    "                      f\"kubectl create --namespace=kubeflow rolebinding \"\n",
    "                       \"--clusterrole=kubeflow-view \"\n",
    "                       \"--serviceaccount=${NAMESPACE}:default-editor \"\n",
    "                       \"${NAMESPACE}-minio-view\")\n",
    "        logging.error(\"API access denied with reason: {e.reason}\")\n",
    "\n",
    "s3_endpoint = minio_service_endpoint\n",
    "s3_endPoint = s3_endpoint+\":9000\"\n",
    "minio_endpoint = \"http://\"+s3_endPoint\n",
    "minio_username = \"minio\"\n",
    "minio_key = \"minio123\"\n",
    "minio_region = \"us-east-1\"\n",
    "print(minio_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MinIO uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_uploader = MinioUploader(endpoint_url=minio_endpoint, minio_secret=minio_username, minio_secret_key=minio_key, region_name=minio_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a MinIO bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_bucket = \"imgzip\"\n",
    "minio_uploader.create_bucket(minio_bucket)\n",
    "logging.info(f\"Bucket {minio_bucket} created or already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Minioclient object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioClient = Minio(s3_endPoint,\n",
    "                    access_key='minio',\n",
    "                    secret_key='minio123',\n",
    "                    secure=False)\n",
    "minioClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload zip file of images into minio bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip_name = 'dataset.zip'\n",
    "print(minioClient.fput_object(minio_bucket, zip_name, zip_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List objects within minio bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = minio_uploader.client.list_objects(Bucket=minio_bucket)\n",
    "#print(model_response)\n",
    "obj_key = model_response['Contents'][0]['Key']\n",
    "print(obj_key)\n",
    "# covid_obj_key = model_response['Contents'][0]['Key']\n",
    "# normal_obj_key = model_response['Contents'][1]['Key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download zip file from minio bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minioClient.fget_object(minio_bucket, covid_obj_key, 'covid_dl.zip')\n",
    "# minioClient.fget_object(minio_bucket, normal_obj_key, 'normal_dl.zip')\n",
    "minioClient.fget_object(minio_bucket, obj_key, 'dataset_dl.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete minio bucket & contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = minio_uploader.client.list_objects(Bucket=minio_bucket)\n",
    "\n",
    "obj_list = []\n",
    "for obj_name in model_response['Contents']:\n",
    "    obj_list.append({'Key' : obj_name['Key']})\n",
    "\n",
    "minio_uploader.client.delete_objects(Bucket=minio_bucket, Delete={'Objects' : obj_list})\n",
    "minio_uploader.client.delete_bucket(Bucket=minio_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response = minio_uploader.client.list_objects(Bucket=minio_bucket)\n",
    "obj_key = list_response['Contents'][0]['Key']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the image dataset zip files from MinIO bucket\n",
    "minioClient.fget_object(minio_bucket, obj_key, 'dataset_dl.zip')\n",
    "\n",
    "#Extract the zip files and store under the same directory\n",
    "with ZipFile('dataset_dl.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of covid zip file into \"image_dataset\" directory\n",
    "   zipObj.extractall('/home/jovyan/dataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
