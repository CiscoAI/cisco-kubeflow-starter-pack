{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class text classification using models\n",
    "\n",
    "This Notebook focuses on implementing multi-class text classification on Amazon automotive reviews dataset by choosing any one combination of various processing techniques and algorithms.\n",
    "\n",
    "Rating(1-5) is predicted for each review from the dataset.\n",
    "\n",
    "Any single combination out of the following can be chosen for model processing & training :\n",
    "\n",
    "* Vectorisation using gensim's word2vec & subsequent training using Random Forest algorithm.\n",
    "* Vectorisation using word2vec and/or Smooth Inverse Frequency (SIF) technique & subsequent training using Random Forest algorithm.\n",
    "* Vectorisation using Term frequency-inverse document frequency (Tfidf) technique & subsequent training using Random Forest algorithm.\n",
    "* Vectorisation using Tfidf technique & subsequent training using Linear support vector clustering (SVC) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.0.5)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.6/site-packages (3.5)\n",
      "Requirement already satisfied: gensim in ./.local/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn==0.20.3 in ./.local/lib/python3.6/site-packages (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.6/site-packages (from nltk) (4.48.0)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.6/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in ./.local/lib/python3.6/site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./.local/lib/python3.6/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: boto3 in ./.local/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.24)\n",
      "Requirement already satisfied: boto in ./.local/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in ./.local/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.24)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in ./.local/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in ./.local/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in ./.local/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk gensim sklearn scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "from joblib import dump\n",
    "import re\n",
    "import nltk as nl\n",
    "import gensim\n",
    "import yaml\n",
    "import os\n",
    "import requests \n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#nltk\n",
    "from nltk.corpus import stopwords\n",
    "nl.download('punkt')\n",
    "nl.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset in JSON format to CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pd.read_json('data/amazon_automotive_reviews.json', lines=True)\n",
    "json_data.to_csv('amazon_automotive_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('amazon_automotive_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3F73SC1LY51OO</td>\n",
       "      <td>B00002243X</td>\n",
       "      <td>Alan Montgomery</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>I needed a set of jumper cables for my new car...</td>\n",
       "      <td>5</td>\n",
       "      <td>Work Well - Should Have Bought Longer Ones</td>\n",
       "      <td>1313539200</td>\n",
       "      <td>08 17, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A20S66SKYXULG2</td>\n",
       "      <td>B00002243X</td>\n",
       "      <td>alphonse</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>These long cables work fine for my truck, but ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Okay long cables</td>\n",
       "      <td>1315094400</td>\n",
       "      <td>09 4, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2I8LFSN2IS5EO</td>\n",
       "      <td>B00002243X</td>\n",
       "      <td>Chris</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Can't comment much on these since they have no...</td>\n",
       "      <td>5</td>\n",
       "      <td>Looks and feels heavy Duty</td>\n",
       "      <td>1374710400</td>\n",
       "      <td>07 25, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3GT2EWQSO45ZG</td>\n",
       "      <td>B00002243X</td>\n",
       "      <td>DeusEx</td>\n",
       "      <td>[19, 19]</td>\n",
       "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent choice for Jumper Cables!!!</td>\n",
       "      <td>1292889600</td>\n",
       "      <td>12 21, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3ESWJPAVRPWB4</td>\n",
       "      <td>B00002243X</td>\n",
       "      <td>E. Hernandez</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased the 12' feet long cable set and th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent, High Quality Starter Cables</td>\n",
       "      <td>1341360000</td>\n",
       "      <td>07 4, 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin     reviewerName   helpful  \\\n",
       "0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n",
       "1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n",
       "2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n",
       "3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n",
       "4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I needed a set of jumper cables for my new car...        5   \n",
       "1  These long cables work fine for my truck, but ...        4   \n",
       "2  Can't comment much on these since they have no...        5   \n",
       "3  I absolutley love Amazon!!!  For the price of ...        5   \n",
       "4  I purchased the 12' feet long cable set and th...        5   \n",
       "\n",
       "                                      summary  unixReviewTime   reviewTime  \n",
       "0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011  \n",
       "1                            Okay long cables      1315094400   09 4, 2011  \n",
       "2                  Looks and feels heavy Duty      1374710400  07 25, 2013  \n",
       "3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010  \n",
       "4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['overallRating'] = raw_data['overall']\n",
    "raw_data = raw_data.drop(['reviewerID','asin','reviewerName','helpful','overall','summary','unixReviewTime','reviewTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overallRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I needed a set of jumper cables for my new car...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These long cables work fine for my truck, but ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can't comment much on these since they have no...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I purchased the 12' feet long cable set and th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overallRating\n",
       "0  I needed a set of jumper cables for my new car...              5\n",
       "1  These long cables work fine for my truck, but ...              4\n",
       "2  Can't comment much on these since they have no...              5\n",
       "3  I absolutley love Amazon!!!  For the price of ...              5\n",
       "4  I purchased the 12' feet long cable set and th...              5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depict class imbalance issue in dataset using value count for each rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    13928\n",
       "4     3967\n",
       "3     1430\n",
       "2      606\n",
       "1      542\n",
       "Name: overallRating, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count = raw_data.overallRating.value_counts()\n",
    "unique_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset to remove class imbalance issue\n",
    "\n",
    "Preprocessing of the dataset is done in such a way that the rating categories of 5 is undersampled and other categories are oversampled accordingly, so as to get a balanced dataset without any prediction output bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 5928 records of rating 5 to be removed\n"
     ]
    }
   ],
   "source": [
    "excess_recs = unique_count[5] - 8000\n",
    "print(\"About %d records of rating 5 to be removed\" %excess_recs)\n",
    "\n",
    "rating_5_excess = raw_data[(raw_data['overallRating'] == 5)]\n",
    "rating_others = raw_data[(raw_data['overallRating'] != 5)]\n",
    "\n",
    "rating_5 = (rating_5_excess.reset_index()).truncate(before=excess_recs)\n",
    "rating_5.set_index('index',inplace=True)\n",
    "\n",
    "raw_data = pd.concat([rating_5,rating_others])\n",
    "\n",
    "rating_1 = raw_data[(raw_data['overallRating'] == 1)]\n",
    "rating_2 = raw_data[(raw_data['overallRating'] == 2)]\n",
    "rating_3 = raw_data[(raw_data['overallRating'] == 3)]\n",
    "rating_4 = raw_data[(raw_data['overallRating'] == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    8000\n",
       "4    5967\n",
       "2    3030\n",
       "3    2860\n",
       "1    2710\n",
       "Name: overallRating, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data = pd.concat([raw_data, rating_1,rating_1,rating_1,rating_1,rating_2,rating_2,rating_2,rating_2,rating_3,rating_4[-2000:]])\n",
    "fin_data.overallRating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['p_review'] = fin_data['reviewText'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overallRating</th>\n",
       "      <th>p_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>KN 33-2370, I have KN's in all my vehicles.  T...</td>\n",
       "      <td>5</td>\n",
       "      <td>KN  I have KNs in all my vehicles  This one is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>This probably the sixth or seventh unique K&amp;N;...</td>\n",
       "      <td>5</td>\n",
       "      <td>This probably the sixth or seventh unique KN f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>I've always been intrigued by K&amp;N filters bein...</td>\n",
       "      <td>5</td>\n",
       "      <td>Ive always been intrigued by KN filters being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>This item is great it fits the vehicle perfect...</td>\n",
       "      <td>5</td>\n",
       "      <td>This item is great it fits the vehicle perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>K&amp;N has always provided consumers with superio...</td>\n",
       "      <td>5</td>\n",
       "      <td>KN has always provided consumers with superior...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  overallRating  \\\n",
       "8170  KN 33-2370, I have KN's in all my vehicles.  T...              5   \n",
       "8171  This probably the sixth or seventh unique K&N;...              5   \n",
       "8172  I've always been intrigued by K&N filters bein...              5   \n",
       "8174  This item is great it fits the vehicle perfect...              5   \n",
       "8175  K&N has always provided consumers with superio...              5   \n",
       "\n",
       "                                               p_review  \n",
       "8170  KN  I have KNs in all my vehicles  This one is...  \n",
       "8171  This probably the sixth or seventh unique KN f...  \n",
       "8172  Ive always been intrigued by KN filters being ...  \n",
       "8174  This item is great it fits the vehicle perfect...  \n",
       "8175  KN has always provided consumers with superior...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model type for training\n",
    "\n",
    "Choose a numeral against the type of model processing & algorithm combinations to use the respective method for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = {  \n",
    "                1 : 'word2vec_rf',\n",
    "                2 : 'sif_rf',\n",
    "                3 : 'tfidf_rf',\n",
    "                4 : 'tfidf_lsvc'\n",
    "             }\n",
    "\n",
    "model_choice = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_choice or model_choice not in range(1,5):\n",
    "     raise ValueError(\"Set a model_choice from 1 to 4 based on model_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize processed review texts while removing stopwords & vectorize the tokens using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if model_choice in [1,2]:\n",
    "\n",
    "        p_review = fin_data['p_review'].to_list()\n",
    "\n",
    "        tokens = [nl.word_tokenize(sentences) for sentences in p_review]\n",
    "\n",
    "        stop_words = stopwords.words('english')\n",
    "\n",
    "        tokens = [[word for word in tokens[i] if not word in stopwords.words('english')] for i in range(len(tokens))]\n",
    "\n",
    "        wv_model = gensim.models.Word2Vec(tokens, size=300, min_count=1, workers=4)\n",
    "\n",
    "        wv_model.train(tokens, total_examples=len(tokens), epochs=50)\n",
    "        \n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess & prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data using word2vec processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "if model_choice == 1:\n",
    "        \n",
    "        print(\"Preparing training data using word2vec processing..\")\n",
    "        wv_train = []\n",
    "        for i in range(len(tokens)):\n",
    "            wv_train.append(np.mean(np.asarray([wv_model[token] for token in tokens[i]]),axis=0))\n",
    "        print(\"Completed\")\n",
    "            \n",
    "elif model_choice == 2:\n",
    "    \n",
    "        print(\"Preparing training data using Smooth inverse frequency(SIF) type processing..\")\n",
    "        vlookup = wv_model.wv.vocab\n",
    "        Z = 0\n",
    "        for k in vlookup:\n",
    "                Z += vlookup[k].count # Compute the normalization constant Z\n",
    "\n",
    "        a = 0.001\n",
    "        embedding_size = 300\n",
    "        wv_sif_train = []\n",
    "        for i in range(len(tokens)):\n",
    "                vs = np.zeros(300)\n",
    "                for word in tokens[i]:\n",
    "                        a_value = a / (a + (vlookup[word].count/Z))\n",
    "                        vs = np.add(vs, np.multiply(a_value, wv_model.wv[word]))\n",
    "                wv_sif_train.append(np.divide(vs, len(tokens[i])))\n",
    "        print(\"Completed\")\n",
    "                \n",
    "else:\n",
    "         print(\"Preparing training data using TfIdf vectorization..\")\n",
    "         tfidf = TfidfVectorizer(ngram_range=(1,2),sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', stop_words='english')\n",
    "         features = tfidf.fit_transform(fin_data.p_review).toarray()\n",
    "         print(features.shape)\n",
    "         print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_choice == 1:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.asarray(wv_train),fin_data['overallRating'],test_size=0.3,shuffle=True,random_state=7)\n",
    "\n",
    "elif model_choice == 2:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.asarray(wv_sif_train),fin_data['overallRating'],test_size=0.2,shuffle=True,random_state=7)\n",
    "\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features,fin_data['overallRating'],test_size=0.3,shuffle=True,random_state=7)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_choice in [1,2,3]:\n",
    "    model = RandomForestClassifier(n_estimators=40, random_state=0)\n",
    "    model.fit(x_train,y_train)\n",
    "    \n",
    "else:\n",
    "    model = LinearSVC()\n",
    "    model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/model.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rel_path = 'model/'\n",
    "file_name = 'model.joblib'\n",
    "\n",
    "if not os.path.exists(file_rel_path):\n",
    "    os.mkdir(file_rel_path)\n",
    "dump(model, file_rel_path + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inference service name & model storage URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvc://workspace-poornima/model/\n"
     ]
    }
   ],
   "source": [
    "svc_name = 'text-classify'\n",
    "\n",
    "!kubectl get pods $HOSTNAME -o yaml -n anonymous > podspec\n",
    "with open(\"podspec\") as f:\n",
    "    content = yaml.safe_load(f)\n",
    "    for elm in content['spec']['volumes']:\n",
    "        if 'workspace-' in elm['name']:\n",
    "            pvc = elm['name']\n",
    "os.remove('podspec')\n",
    "pvc\n",
    "    \n",
    "storageURI = \"pvc://\" + pvc + '/' + file_rel_path\n",
    "print(storageURI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define configuration for inference service creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: serving.kubeflow.org/v1alpha2\r\n",
      "kind: InferenceService\r\n",
      "metadata:\r\n",
      "  name: text-classify\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      sklearn:\r\n",
      "        storageUri: pvc://workspace-poornima/model/\r\n"
     ]
    }
   ],
   "source": [
    "wsvol_blerssi_kf = f\"\"\"apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: {svc_name}\n",
    "  namespace: anonymous\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      sklearn:\n",
    "        storageUri: {storageURI}\n",
    "\"\"\"\n",
    "    \n",
    "kfserving = yaml.safe_load(wsvol_blerssi_kf)\n",
    "with open('blerssi-kfserving.yaml', 'w') as file:\n",
    "    yaml_kfserving = yaml.dump(kfserving,file)\n",
    "\n",
    "! cat blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the configuration .yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/text-classify unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether inferenceservice is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "text-classify   http://text-classify.anonymous.example.com/v1/models/text-classify   True    100                                12m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservice -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "Wait for inference service READY=\"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict data from serving after setting INGRESS_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_name = svc_name + '.anonymous.example.com'\n",
    "\n",
    "headers = { \n",
    "    'host': host_name\n",
    "}\n",
    "\n",
    "formData = {\n",
    "    'instances': x_test[:1].tolist()\n",
    "}\n",
    "\n",
    "url = 'http://<<INGRESS_IP>>:31380/v1/models/' + svc_name + ':predict'\n",
    "res = requests.post(url, json=formData, headers=headers)\n",
    "results = res.json()\n",
    "prediction = results['predictions']\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up after predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org \"text-classify\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f blerssi-kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $file_rel_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
